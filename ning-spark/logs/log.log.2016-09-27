2016-09-27 09:52:11  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 09:52:13  [ ScalaTest-run:1862 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 09:52:14  [ ScalaTest-run:2854 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 09:52:14  [ ScalaTest-run:2858 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 09:52:14  [ ScalaTest-run:2861 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 09:52:16  [ ScalaTest-run:5189 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 60101.
2016-09-27 09:52:17  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:6352 ] - [ INFO ]  Slf4jLogger started
2016-09-27 09:52:17  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:6688 ] - [ INFO ]  Starting remoting
2016-09-27 09:52:18  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:7366 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:60114]
2016-09-27 09:52:18  [ ScalaTest-run:7379 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 60114.
2016-09-27 09:52:18  [ ScalaTest-run:7457 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 09:52:18  [ ScalaTest-run:7563 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 09:52:18  [ ScalaTest-run:7614 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-c34c2619-4f04-4240-ad41-66c9696dae4f
2016-09-27 09:52:18  [ ScalaTest-run:7687 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 09:52:19  [ ScalaTest-run:7997 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 09:52:20  [ ScalaTest-run:8997 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 09:52:20  [ ScalaTest-run:9166 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4040
2016-09-27 09:52:20  [ ScalaTest-run:9167 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2016-09-27 09:52:20  [ ScalaTest-run:9179 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4040
2016-09-27 09:52:21  [ ScalaTest-run:10607 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 09:52:22  [ ScalaTest-run:10778 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60134.
2016-09-27 09:52:22  [ ScalaTest-run:10782 ] - [ INFO ]  Server created on 60134
2016-09-27 09:52:22  [ ScalaTest-run:10793 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 09:52:22  [ dispatcher-event-loop-2:10808 ] - [ INFO ]  Registering block manager localhost:60134 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 60134)
2016-09-27 09:52:22  [ ScalaTest-run:10824 ] - [ INFO ]  Registered BlockManager
2016-09-27 09:52:23  [ ScalaTest-run-running-RDDSuite:12597 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 09:52:25  [ ScalaTest-run-running-RDDSuite:14181 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 09:52:25  [ ScalaTest-run-running-RDDSuite:14286 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 09:52:25  [ dispatcher-event-loop-0:14296 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:60134 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 09:52:25  [ ScalaTest-run-running-RDDSuite:14522 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 09:52:26  [ ScalaTest-run-running-RDDSuite:14906 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 09:52:27  [ ScalaTest-run-running-RDDSuite:16583 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 09:52:29  [ ScalaTest-run-running-RDDSuite:18268 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 09:52:30  [ ScalaTest-run-running-RDDSuite:19622 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 09:52:33  [ dag-scheduler-event-loop:22592 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 09:52:33  [ dag-scheduler-event-loop:22599 ] - [ INFO ]  Registering RDD 5 (map at RDDSuite.scala:262)
2016-09-27 09:52:42  [ dag-scheduler-event-loop:31156 ] - [ INFO ]  Got job 0 (collect at RDDSuite.scala:264) with 3 output partitions
2016-09-27 09:52:43  [ dag-scheduler-event-loop:31824 ] - [ INFO ]  Final stage: ResultStage 2 (collect at RDDSuite.scala:264)
2016-09-27 09:52:44  [ dag-scheduler-event-loop:32840 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 1)
2016-09-27 09:53:30  [ dag-scheduler-event-loop:78811 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 1)
2016-09-27 09:53:30  [ driver-heartbeater:78997 ] - [ WARN ]  Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@75c74dbe,BlockManagerId(driver, localhost, 60134))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:449)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1765)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:470)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:107)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:107)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2016-09-27 09:53:31  [ heartbeat-receiver-event-loop-thread:80361 ] - [ WARN ]  Ignored message: HeartbeatResponse(false)
2016-09-27 10:05:17  [ dispatcher-event-loop-0:786242 ] - [ WARN ]  Removing executor driver with no recent heartbeats: 578341 ms exceeds timeout 120000 ms
2016-09-27 10:05:17  [ dispatcher-event-loop-0:786251 ] - [ ERROR ]  Lost an executor driver (already removed): Executor heartbeat timed out after 578341 ms
2016-09-27 10:11:03  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:11:04  [ ScalaTest-run:911 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:11:04  [ ScalaTest-run:1428 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:11:04  [ ScalaTest-run:1429 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:11:04  [ ScalaTest-run:1431 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:11:06  [ ScalaTest-run:2792 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 60514.
2016-09-27 10:11:07  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3586 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:11:07  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3778 ] - [ INFO ]  Starting remoting
2016-09-27 10:11:07  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4397 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:60527]
2016-09-27 10:11:08  [ ScalaTest-run:4577 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 60527.
2016-09-27 10:11:08  [ ScalaTest-run:4726 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:11:08  [ ScalaTest-run:4868 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:11:08  [ ScalaTest-run:4897 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-43dcad98-96f8-4c73-9375-10ab9ab306e0
2016-09-27 10:11:08  [ ScalaTest-run:4960 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:11:08  [ ScalaTest-run:5240 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:11:09  [ ScalaTest-run:6281 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:11:09  [ ScalaTest-run:6348 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:11:09  [ ScalaTest-run:6354 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@6d0be7ab: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:11:09  [ ScalaTest-run:6360 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:11:09  [ ScalaTest-run:6362 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:11:09  [ ScalaTest-run:6362 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:11:09  [ ScalaTest-run:6363 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:11:09  [ ScalaTest-run:6363 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6363 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:11:09  [ ScalaTest-run:6363 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6364 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:11:09  [ ScalaTest-run:6364 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6364 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:11:09  [ ScalaTest-run:6365 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6365 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:11:09  [ ScalaTest-run:6365 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6366 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:11:09  [ ScalaTest-run:6366 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6366 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:11:09  [ ScalaTest-run:6366 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6367 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:11:09  [ ScalaTest-run:6367 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6367 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:11:09  [ ScalaTest-run:6368 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6369 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:11:09  [ ScalaTest-run:6369 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:11:09  [ ScalaTest-run:6369 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:11:10  [ ScalaTest-run:6494 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:11:10  [ ScalaTest-run:6495 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:11:10  [ ScalaTest-run:6562 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:11:10  [ ScalaTest-run:6563 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:11:10  [ ScalaTest-run:6570 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:11:10  [ ScalaTest-run:7088 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:11:10  [ ScalaTest-run:7164 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60546.
2016-09-27 10:11:10  [ ScalaTest-run:7166 ] - [ INFO ]  Server created on 60546
2016-09-27 10:11:10  [ ScalaTest-run:7171 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:11:10  [ dispatcher-event-loop-2:7182 ] - [ INFO ]  Registering block manager localhost:60546 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 60546)
2016-09-27 10:11:10  [ ScalaTest-run:7188 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:11:11  [ ScalaTest-run-running-RDDSuite:8236 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:11:12  [ ScalaTest-run-running-RDDSuite:9344 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:11:12  [ ScalaTest-run-running-RDDSuite:9433 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:11:12  [ dispatcher-event-loop-0:9441 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:60546 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:11:13  [ ScalaTest-run-running-RDDSuite:9505 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:11:13  [ ScalaTest-run-running-RDDSuite:9951 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:11:15  [ ScalaTest-run-running-RDDSuite:11477 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:11:16  [ ScalaTest-run-running-RDDSuite:13094 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:11:17  [ ScalaTest-run-running-RDDSuite:13852 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:11:25  [ dag-scheduler-event-loop:22418 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 10:11:25  [ dag-scheduler-event-loop:22426 ] - [ INFO ]  Registering RDD 5 (map at RDDSuite.scala:262)
2016-09-27 10:13:52  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:13:54  [ ScalaTest-run:1233 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:13:54  [ ScalaTest-run:1710 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:13:54  [ ScalaTest-run:1712 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:13:54  [ ScalaTest-run:1714 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:13:56  [ ScalaTest-run:3909 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 60587.
2016-09-27 10:13:58  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:5147 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:13:58  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:5369 ] - [ INFO ]  Starting remoting
2016-09-27 10:13:58  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:6039 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:60600]
2016-09-27 10:13:58  [ ScalaTest-run:6058 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 60600.
2016-09-27 10:13:58  [ ScalaTest-run:6132 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:13:59  [ ScalaTest-run:6239 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:13:59  [ ScalaTest-run:6293 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-d15a39b3-13ab-48c2-bfe6-6076d38f40a8
2016-09-27 10:13:59  [ ScalaTest-run:6378 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:13:59  [ ScalaTest-run:6698 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:14:00  [ ScalaTest-run:7340 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:14:00  [ ScalaTest-run:7425 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:14:00  [ ScalaTest-run:7433 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@12b5736c: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:14:00  [ ScalaTest-run:7442 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:14:00  [ ScalaTest-run:7442 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:14:00  [ ScalaTest-run:7443 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:14:00  [ ScalaTest-run:7443 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:14:00  [ ScalaTest-run:7443 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7444 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:14:00  [ ScalaTest-run:7444 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7444 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:14:00  [ ScalaTest-run:7445 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7445 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:14:00  [ ScalaTest-run:7445 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7446 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:14:00  [ ScalaTest-run:7446 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7446 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:14:00  [ ScalaTest-run:7447 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7447 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:14:00  [ ScalaTest-run:7448 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7448 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:14:00  [ ScalaTest-run:7448 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7449 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:14:00  [ ScalaTest-run:7449 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7449 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:14:00  [ ScalaTest-run:7450 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:14:00  [ ScalaTest-run:7450 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:14:00  [ ScalaTest-run:7505 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:14:00  [ ScalaTest-run:7506 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:14:00  [ ScalaTest-run:7530 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:14:00  [ ScalaTest-run:7531 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:14:00  [ ScalaTest-run:7537 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:14:01  [ ScalaTest-run:8271 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:14:01  [ ScalaTest-run:8394 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60620.
2016-09-27 10:14:01  [ ScalaTest-run:8397 ] - [ INFO ]  Server created on 60620
2016-09-27 10:14:01  [ ScalaTest-run:8405 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:14:01  [ dispatcher-event-loop-2:8417 ] - [ INFO ]  Registering block manager localhost:60620 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 60620)
2016-09-27 10:14:01  [ ScalaTest-run:8425 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:14:02  [ ScalaTest-run-running-RDDSuite:9926 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:14:04  [ ScalaTest-run-running-RDDSuite:11576 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:14:04  [ ScalaTest-run-running-RDDSuite:11714 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:14:04  [ dispatcher-event-loop-0:11726 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:60620 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:14:04  [ ScalaTest-run-running-RDDSuite:11824 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:14:05  [ ScalaTest-run-running-RDDSuite:12350 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:14:07  [ ScalaTest-run-running-RDDSuite:14191 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:14:08  [ ScalaTest-run-running-RDDSuite:15873 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:14:09  [ ScalaTest-run-running-RDDSuite:16631 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:18:16  [ dag-scheduler-event-loop:263803 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 10:19:32  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:19:33  [ ScalaTest-run:1115 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:19:34  [ ScalaTest-run:1670 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:19:34  [ ScalaTest-run:1673 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:19:34  [ ScalaTest-run:1676 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:19:35  [ ScalaTest-run:3327 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 60702.
2016-09-27 10:19:37  [ sparkDriverActorSystem-akka.actor.default-dispatcher-3:4700 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:19:37  [ sparkDriverActorSystem-akka.actor.default-dispatcher-3:4937 ] - [ INFO ]  Starting remoting
2016-09-27 10:19:38  [ sparkDriverActorSystem-akka.actor.default-dispatcher-3:5493 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:60716]
2016-09-27 10:19:38  [ ScalaTest-run:5500 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 60716.
2016-09-27 10:19:38  [ ScalaTest-run:5565 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:19:38  [ ScalaTest-run:5635 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:19:38  [ ScalaTest-run:5662 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-8baaf884-ea95-4504-94de-1041ed801736
2016-09-27 10:19:38  [ ScalaTest-run:5726 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:19:38  [ ScalaTest-run:5951 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:19:38  [ ScalaTest-run:6426 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:19:39  [ ScalaTest-run:6488 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:19:39  [ ScalaTest-run:6494 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@650c405c: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:19:39  [ ScalaTest-run:6500 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:19:39  [ ScalaTest-run:6500 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:19:39  [ ScalaTest-run:6501 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:19:39  [ ScalaTest-run:6501 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:19:39  [ ScalaTest-run:6501 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6501 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:19:39  [ ScalaTest-run:6502 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6502 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:19:39  [ ScalaTest-run:6502 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6502 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:19:39  [ ScalaTest-run:6503 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6503 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:19:39  [ ScalaTest-run:6503 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6504 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:19:39  [ ScalaTest-run:6504 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6504 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:19:39  [ ScalaTest-run:6504 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6505 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:19:39  [ ScalaTest-run:6505 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6505 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:19:39  [ ScalaTest-run:6506 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6506 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:19:39  [ ScalaTest-run:6506 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:19:39  [ ScalaTest-run:6506 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:19:39  [ ScalaTest-run:6562 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:19:39  [ ScalaTest-run:6564 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:19:39  [ ScalaTest-run:6585 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:19:39  [ ScalaTest-run:6586 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:19:39  [ ScalaTest-run:6591 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:19:39  [ ScalaTest-run:7228 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:19:39  [ ScalaTest-run:7294 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60745.
2016-09-27 10:19:39  [ ScalaTest-run:7296 ] - [ INFO ]  Server created on 60745
2016-09-27 10:19:39  [ ScalaTest-run:7299 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:19:39  [ dispatcher-event-loop-2:7306 ] - [ INFO ]  Registering block manager localhost:60745 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 60745)
2016-09-27 10:19:39  [ ScalaTest-run:7311 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:19:40  [ ScalaTest-run-running-RDDSuite:8143 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:19:41  [ ScalaTest-run-running-RDDSuite:9050 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:19:41  [ ScalaTest-run-running-RDDSuite:9130 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:19:41  [ dispatcher-event-loop-0:9137 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:60745 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:19:41  [ ScalaTest-run-running-RDDSuite:9201 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:19:42  [ ScalaTest-run-running-RDDSuite:9521 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:19:43  [ ScalaTest-run-running-RDDSuite:11320 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:19:45  [ ScalaTest-run-running-RDDSuite:12952 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:19:46  [ ScalaTest-run-running-RDDSuite:13734 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:23:33  [ driver-heartbeater:240442 ] - [ WARN ]  Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2e64af6d,BlockManagerId(driver, localhost, 60745))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:449)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1765)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:470)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:107)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:107)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2016-09-27 10:23:33  [ heartbeat-receiver-event-loop-thread:240458 ] - [ WARN ]  Ignored message: HeartbeatResponse(false)
2016-09-27 10:28:14  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:28:15  [ ScalaTest-run:1270 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:28:15  [ ScalaTest-run:1958 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:28:15  [ ScalaTest-run:1959 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:28:15  [ ScalaTest-run:1961 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:28:17  [ ScalaTest-run:3313 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 60829.
2016-09-27 10:28:18  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:4005 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:28:18  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:4178 ] - [ INFO ]  Starting remoting
2016-09-27 10:28:18  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:4650 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:60842]
2016-09-27 10:28:18  [ ScalaTest-run:4673 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 60842.
2016-09-27 10:28:18  [ ScalaTest-run:4722 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:28:18  [ ScalaTest-run:4804 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:28:18  [ ScalaTest-run:4845 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-edb801ee-bad7-4220-b27b-d6b52d43af31
2016-09-27 10:28:18  [ ScalaTest-run:4912 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:28:19  [ ScalaTest-run:5155 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:28:19  [ ScalaTest-run:5545 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:28:19  [ ScalaTest-run:5597 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:28:19  [ ScalaTest-run:5604 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@798256c5: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:28:19  [ ScalaTest-run:5609 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:28:19  [ ScalaTest-run:5609 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:28:19  [ ScalaTest-run:5609 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:28:19  [ ScalaTest-run:5610 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:28:19  [ ScalaTest-run:5610 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5610 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:28:19  [ ScalaTest-run:5610 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5610 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:28:19  [ ScalaTest-run:5611 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5611 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:28:19  [ ScalaTest-run:5611 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5611 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:28:19  [ ScalaTest-run:5611 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5612 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:28:19  [ ScalaTest-run:5612 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5612 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:28:19  [ ScalaTest-run:5612 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5612 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:28:19  [ ScalaTest-run:5612 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5613 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:28:19  [ ScalaTest-run:5613 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5613 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:28:19  [ ScalaTest-run:5613 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:28:19  [ ScalaTest-run:5614 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:28:19  [ ScalaTest-run:5668 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:28:19  [ ScalaTest-run:5669 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:28:19  [ ScalaTest-run:5687 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:28:19  [ ScalaTest-run:5688 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:28:19  [ ScalaTest-run:5693 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:28:20  [ ScalaTest-run:6326 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:28:20  [ ScalaTest-run:6406 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60862.
2016-09-27 10:28:20  [ ScalaTest-run:6408 ] - [ INFO ]  Server created on 60862
2016-09-27 10:28:20  [ ScalaTest-run:6413 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:28:20  [ dispatcher-event-loop-2:6421 ] - [ INFO ]  Registering block manager localhost:60862 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 60862)
2016-09-27 10:28:20  [ ScalaTest-run:6427 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:28:21  [ ScalaTest-run-running-RDDSuite:7228 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:28:22  [ ScalaTest-run-running-RDDSuite:8118 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:28:22  [ ScalaTest-run-running-RDDSuite:8185 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:28:22  [ dispatcher-event-loop-0:8191 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:60862 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:28:22  [ ScalaTest-run-running-RDDSuite:8249 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:28:22  [ ScalaTest-run-running-RDDSuite:8506 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:28:24  [ ScalaTest-run-running-RDDSuite:10262 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:28:25  [ ScalaTest-run-running-RDDSuite:11901 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:28:26  [ ScalaTest-run-running-RDDSuite:12769 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:32:57  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:32:58  [ ScalaTest-run:898 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:32:58  [ ScalaTest-run:1310 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:32:58  [ ScalaTest-run:1312 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:32:58  [ ScalaTest-run:1313 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:32:59  [ ScalaTest-run:2801 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 60910.
2016-09-27 10:33:00  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3729 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:33:01  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3906 ] - [ INFO ]  Starting remoting
2016-09-27 10:33:01  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4489 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:60924]
2016-09-27 10:33:01  [ ScalaTest-run:4508 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 60924.
2016-09-27 10:33:01  [ ScalaTest-run:4566 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:33:01  [ ScalaTest-run:4651 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:33:01  [ ScalaTest-run:4686 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-ca327431-43e3-449b-9f7d-910fca567a58
2016-09-27 10:33:01  [ ScalaTest-run:4745 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:33:02  [ ScalaTest-run:4953 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:33:03  [ ScalaTest-run:5966 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:33:03  [ ScalaTest-run:6025 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:33:03  [ ScalaTest-run:6029 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@34a2d6e0: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:33:03  [ ScalaTest-run:6035 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:33:03  [ ScalaTest-run:6036 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:33:03  [ ScalaTest-run:6036 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:33:03  [ ScalaTest-run:6036 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:33:03  [ ScalaTest-run:6037 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6037 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:33:03  [ ScalaTest-run:6037 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6038 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:33:03  [ ScalaTest-run:6038 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6038 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:33:03  [ ScalaTest-run:6038 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6039 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:33:03  [ ScalaTest-run:6039 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6039 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:33:03  [ ScalaTest-run:6039 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6040 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:33:03  [ ScalaTest-run:6040 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6040 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:33:03  [ ScalaTest-run:6040 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6041 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:33:03  [ ScalaTest-run:6041 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6041 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:33:03  [ ScalaTest-run:6042 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:33:03  [ ScalaTest-run:6042 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:33:03  [ ScalaTest-run:6099 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:33:03  [ ScalaTest-run:6100 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:33:03  [ ScalaTest-run:6117 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:33:03  [ ScalaTest-run:6118 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:33:03  [ ScalaTest-run:6122 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:33:04  [ ScalaTest-run:6922 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:33:04  [ ScalaTest-run:6987 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60948.
2016-09-27 10:33:04  [ ScalaTest-run:6989 ] - [ INFO ]  Server created on 60948
2016-09-27 10:33:04  [ ScalaTest-run:6992 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:33:04  [ dispatcher-event-loop-2:6997 ] - [ INFO ]  Registering block manager localhost:60948 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 60948)
2016-09-27 10:33:04  [ ScalaTest-run:7003 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:33:05  [ ScalaTest-run-running-RDDSuite:8170 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:33:07  [ ScalaTest-run-running-RDDSuite:9855 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:33:07  [ ScalaTest-run-running-RDDSuite:10012 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:33:07  [ dispatcher-event-loop-0:10023 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:60948 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:33:07  [ ScalaTest-run-running-RDDSuite:10112 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:33:07  [ ScalaTest-run-running-RDDSuite:10566 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:33:09  [ ScalaTest-run-running-RDDSuite:12331 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:33:11  [ ScalaTest-run-running-RDDSuite:14210 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:33:12  [ ScalaTest-run-running-RDDSuite:14944 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:34:40  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:34:41  [ ScalaTest-run:1247 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:34:42  [ ScalaTest-run:1874 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:34:42  [ ScalaTest-run:1876 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:34:42  [ ScalaTest-run:1878 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:34:43  [ ScalaTest-run:3607 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 60990.
2016-09-27 10:34:44  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4607 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:34:44  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4736 ] - [ INFO ]  Starting remoting
2016-09-27 10:34:45  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:5135 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61003]
2016-09-27 10:34:45  [ ScalaTest-run:5155 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61003.
2016-09-27 10:34:45  [ ScalaTest-run:5201 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:34:45  [ ScalaTest-run:5277 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:34:45  [ ScalaTest-run:5313 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-5b292e51-1f76-4212-935b-a4b839800eb4
2016-09-27 10:34:45  [ ScalaTest-run:5413 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:34:45  [ ScalaTest-run:5675 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:34:46  [ ScalaTest-run:6127 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:34:46  [ ScalaTest-run:6180 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:34:46  [ ScalaTest-run:6185 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@46039a21: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:34:46  [ ScalaTest-run:6191 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:34:46  [ ScalaTest-run:6192 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:34:46  [ ScalaTest-run:6192 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:34:46  [ ScalaTest-run:6192 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:34:46  [ ScalaTest-run:6192 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6192 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:34:46  [ ScalaTest-run:6193 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6193 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:34:46  [ ScalaTest-run:6193 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6193 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:34:46  [ ScalaTest-run:6193 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6194 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:34:46  [ ScalaTest-run:6194 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6194 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:34:46  [ ScalaTest-run:6194 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6194 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:34:46  [ ScalaTest-run:6194 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6195 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:34:46  [ ScalaTest-run:6195 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6195 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:34:46  [ ScalaTest-run:6195 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6196 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:34:46  [ ScalaTest-run:6196 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:34:46  [ ScalaTest-run:6196 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:34:46  [ ScalaTest-run:6250 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:34:46  [ ScalaTest-run:6251 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:34:46  [ ScalaTest-run:6269 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:34:46  [ ScalaTest-run:6269 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:34:46  [ ScalaTest-run:6274 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:34:46  [ ScalaTest-run:6792 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:34:46  [ ScalaTest-run:6857 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61022.
2016-09-27 10:34:46  [ ScalaTest-run:6858 ] - [ INFO ]  Server created on 61022
2016-09-27 10:34:47  [ ScalaTest-run:6862 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:34:47  [ dispatcher-event-loop-2:6867 ] - [ INFO ]  Registering block manager localhost:61022 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61022)
2016-09-27 10:34:47  [ ScalaTest-run:6872 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:34:47  [ ScalaTest-run-running-RDDSuite:7613 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:34:48  [ ScalaTest-run-running-RDDSuite:8432 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:34:48  [ ScalaTest-run-running-RDDSuite:8492 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:34:48  [ dispatcher-event-loop-0:8499 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61022 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:34:48  [ ScalaTest-run-running-RDDSuite:8557 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:34:48  [ ScalaTest-run-running-RDDSuite:8799 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:34:50  [ ScalaTest-run-running-RDDSuite:10545 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:34:52  [ ScalaTest-run-running-RDDSuite:12229 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:34:53  [ ScalaTest-run-running-RDDSuite:12962 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:35:49  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:35:50  [ ScalaTest-run:1340 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:35:50  [ ScalaTest-run:1781 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:35:50  [ ScalaTest-run:1782 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:35:50  [ ScalaTest-run:1783 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:35:52  [ ScalaTest-run:3158 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 61054.
2016-09-27 10:35:53  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:4551 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:35:54  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:4868 ] - [ INFO ]  Starting remoting
2016-09-27 10:35:54  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:5481 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61069]
2016-09-27 10:35:54  [ ScalaTest-run:5505 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61069.
2016-09-27 10:35:54  [ ScalaTest-run:5598 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:35:54  [ ScalaTest-run:5707 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:35:54  [ ScalaTest-run:5773 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-703dde98-1560-417d-ac7b-a26358d2386d
2016-09-27 10:35:54  [ ScalaTest-run:5860 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:35:55  [ ScalaTest-run:6197 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:35:55  [ ScalaTest-run:6850 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:35:56  [ ScalaTest-run:6920 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:35:56  [ ScalaTest-run:6928 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@49cb1baf: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:35:56  [ ScalaTest-run:6933 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:35:56  [ ScalaTest-run:6934 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:35:56  [ ScalaTest-run:6934 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:35:56  [ ScalaTest-run:6934 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:35:56  [ ScalaTest-run:6934 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6935 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:35:56  [ ScalaTest-run:6935 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6935 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:35:56  [ ScalaTest-run:6936 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6936 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:35:56  [ ScalaTest-run:6936 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6937 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:35:56  [ ScalaTest-run:6937 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6937 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:35:56  [ ScalaTest-run:6938 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6938 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:35:56  [ ScalaTest-run:6939 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6939 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:35:56  [ ScalaTest-run:6940 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6940 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:35:56  [ ScalaTest-run:6940 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6941 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:35:56  [ ScalaTest-run:6941 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:35:56  [ ScalaTest-run:6942 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:35:56  [ ScalaTest-run:6996 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:35:56  [ ScalaTest-run:6998 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:35:56  [ ScalaTest-run:7018 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:35:56  [ ScalaTest-run:7019 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:35:56  [ ScalaTest-run:7027 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:35:56  [ ScalaTest-run:7698 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:35:56  [ ScalaTest-run:7786 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61088.
2016-09-27 10:35:56  [ ScalaTest-run:7788 ] - [ INFO ]  Server created on 61088
2016-09-27 10:35:56  [ ScalaTest-run:7795 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:35:56  [ dispatcher-event-loop-1:7802 ] - [ INFO ]  Registering block manager localhost:61088 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61088)
2016-09-27 10:35:56  [ ScalaTest-run:7808 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:35:58  [ ScalaTest-run-running-RDDSuite:8951 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:35:59  [ ScalaTest-run-running-RDDSuite:10076 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:35:59  [ ScalaTest-run-running-RDDSuite:10163 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:35:59  [ dispatcher-event-loop-0:10172 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61088 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:35:59  [ ScalaTest-run-running-RDDSuite:10237 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:35:59  [ ScalaTest-run-running-RDDSuite:10535 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:36:01  [ ScalaTest-run-running-RDDSuite:12241 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:36:03  [ ScalaTest-run-running-RDDSuite:13908 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:36:03  [ ScalaTest-run-running-RDDSuite:14705 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:41:42  [ dag-scheduler-event-loop:353271 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 10:43:06  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:43:07  [ ScalaTest-run:1213 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:43:07  [ ScalaTest-run:1701 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:43:07  [ ScalaTest-run:1704 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:43:07  [ ScalaTest-run:1707 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:43:09  [ ScalaTest-run:3298 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 61154.
2016-09-27 10:43:10  [ sparkDriverActorSystem-akka.actor.default-dispatcher-3:4059 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:43:10  [ sparkDriverActorSystem-akka.actor.default-dispatcher-3:4206 ] - [ INFO ]  Starting remoting
2016-09-27 10:43:10  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:4607 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61167]
2016-09-27 10:43:10  [ ScalaTest-run:4631 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61167.
2016-09-27 10:43:10  [ ScalaTest-run:4689 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:43:10  [ ScalaTest-run:4767 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:43:10  [ ScalaTest-run:4803 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-8c4dd54a-a8df-4a80-aba1-ef4a3d21bc33
2016-09-27 10:43:10  [ ScalaTest-run:4873 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:43:11  [ ScalaTest-run:5060 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:43:11  [ ScalaTest-run:5565 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:43:11  [ ScalaTest-run:5623 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:43:11  [ ScalaTest-run:5628 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@6d33a66e: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:43:11  [ ScalaTest-run:5635 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:43:11  [ ScalaTest-run:5635 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:43:11  [ ScalaTest-run:5636 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:43:11  [ ScalaTest-run:5636 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:43:11  [ ScalaTest-run:5636 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5636 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:43:11  [ ScalaTest-run:5637 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5637 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:43:11  [ ScalaTest-run:5637 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5637 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:43:11  [ ScalaTest-run:5638 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5638 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:43:11  [ ScalaTest-run:5638 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5638 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:43:11  [ ScalaTest-run:5639 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5639 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:43:11  [ ScalaTest-run:5639 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5639 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:43:11  [ ScalaTest-run:5639 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5640 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:43:11  [ ScalaTest-run:5640 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5640 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:43:11  [ ScalaTest-run:5640 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:43:11  [ ScalaTest-run:5641 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:43:11  [ ScalaTest-run:5695 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:43:11  [ ScalaTest-run:5697 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:43:11  [ ScalaTest-run:5714 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:43:11  [ ScalaTest-run:5787 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:43:11  [ ScalaTest-run:5795 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:43:12  [ ScalaTest-run:6365 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:43:12  [ ScalaTest-run:6434 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61187.
2016-09-27 10:43:12  [ ScalaTest-run:6436 ] - [ INFO ]  Server created on 61187
2016-09-27 10:43:12  [ ScalaTest-run:6440 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:43:12  [ dispatcher-event-loop-0:6446 ] - [ INFO ]  Registering block manager localhost:61187 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61187)
2016-09-27 10:43:12  [ ScalaTest-run:6451 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:43:13  [ ScalaTest-run-running-RDDSuite:7269 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:43:14  [ ScalaTest-run-running-RDDSuite:8170 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:43:14  [ ScalaTest-run-running-RDDSuite:8239 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:43:14  [ dispatcher-event-loop-1:8245 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61187 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:43:14  [ ScalaTest-run-running-RDDSuite:8309 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:43:14  [ ScalaTest-run-running-RDDSuite:8557 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:43:16  [ ScalaTest-run-running-RDDSuite:10336 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:43:18  [ ScalaTest-run-running-RDDSuite:12209 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:43:19  [ ScalaTest-run-running-RDDSuite:13109 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:45:48  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:45:49  [ ScalaTest-run:923 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:45:49  [ ScalaTest-run:1321 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:45:49  [ ScalaTest-run:1323 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:45:49  [ ScalaTest-run:1325 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:45:50  [ ScalaTest-run:2602 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 61235.
2016-09-27 10:45:51  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:3276 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:45:51  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:3392 ] - [ INFO ]  Starting remoting
2016-09-27 10:45:52  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:3805 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61248]
2016-09-27 10:45:52  [ ScalaTest-run:3819 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61248.
2016-09-27 10:45:52  [ ScalaTest-run:3870 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:45:52  [ ScalaTest-run:3969 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:45:52  [ ScalaTest-run:4012 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-e7c550cb-f201-41ec-9fe2-c5666ded202a
2016-09-27 10:45:52  [ ScalaTest-run:4073 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:45:52  [ ScalaTest-run:4379 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:45:53  [ ScalaTest-run:4830 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:45:53  [ ScalaTest-run:4879 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:45:53  [ ScalaTest-run:4883 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@12b5736c: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:45:53  [ ScalaTest-run:4890 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:45:53  [ ScalaTest-run:4891 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:45:53  [ ScalaTest-run:4891 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:45:53  [ ScalaTest-run:4892 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:45:53  [ ScalaTest-run:4892 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4892 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:45:53  [ ScalaTest-run:4892 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4893 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:45:53  [ ScalaTest-run:4893 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4893 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:45:53  [ ScalaTest-run:4893 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4894 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:45:53  [ ScalaTest-run:4894 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4894 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:45:53  [ ScalaTest-run:4894 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4895 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:45:53  [ ScalaTest-run:4895 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4895 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:45:53  [ ScalaTest-run:4895 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4896 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:45:53  [ ScalaTest-run:4896 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4896 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:45:53  [ ScalaTest-run:4897 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:45:53  [ ScalaTest-run:4897 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:45:53  [ ScalaTest-run:4951 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:45:53  [ ScalaTest-run:4952 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:45:53  [ ScalaTest-run:4967 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:45:53  [ ScalaTest-run:4968 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:45:53  [ ScalaTest-run:4972 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:45:53  [ ScalaTest-run:5482 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:45:53  [ ScalaTest-run:5547 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61267.
2016-09-27 10:45:53  [ ScalaTest-run:5549 ] - [ INFO ]  Server created on 61267
2016-09-27 10:45:53  [ ScalaTest-run:5552 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:45:53  [ dispatcher-event-loop-2:5558 ] - [ INFO ]  Registering block manager localhost:61267 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61267)
2016-09-27 10:45:53  [ ScalaTest-run:5562 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:45:55  [ ScalaTest-run-running-RDDSuite:6736 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:45:56  [ ScalaTest-run-running-RDDSuite:8311 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:45:56  [ ScalaTest-run-running-RDDSuite:8432 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:45:56  [ dispatcher-event-loop-0:8446 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61267 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:45:56  [ ScalaTest-run-running-RDDSuite:8551 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:45:57  [ ScalaTest-run-running-RDDSuite:8968 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:45:59  [ ScalaTest-run-running-RDDSuite:10730 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:46:00  [ ScalaTest-run-running-RDDSuite:12465 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:46:01  [ ScalaTest-run-running-RDDSuite:13317 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:51:26  [ dag-scheduler-event-loop:337924 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 10:53:05  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:53:06  [ ScalaTest-run:1180 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:53:07  [ ScalaTest-run:1896 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:53:07  [ ScalaTest-run:1899 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:53:07  [ ScalaTest-run:1902 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:53:09  [ ScalaTest-run:3339 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 61336.
2016-09-27 10:53:09  [ sparkDriverActorSystem-akka.actor.default-dispatcher-3:4168 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:53:10  [ sparkDriverActorSystem-akka.actor.default-dispatcher-3:4321 ] - [ INFO ]  Starting remoting
2016-09-27 10:53:10  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4806 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61349]
2016-09-27 10:53:10  [ ScalaTest-run:4829 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61349.
2016-09-27 10:53:10  [ ScalaTest-run:4875 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:53:10  [ ScalaTest-run:4949 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:53:10  [ ScalaTest-run:4985 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-2b447fcf-50a7-4ff6-b902-801a4145136c
2016-09-27 10:53:10  [ ScalaTest-run:5055 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:53:11  [ ScalaTest-run:5230 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:53:11  [ ScalaTest-run:5611 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:53:11  [ ScalaTest-run:5664 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:53:11  [ ScalaTest-run:5669 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@66de00f2: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:53:11  [ ScalaTest-run:5673 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:53:11  [ ScalaTest-run:5674 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:53:11  [ ScalaTest-run:5674 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:53:11  [ ScalaTest-run:5675 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:53:11  [ ScalaTest-run:5675 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5675 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:53:11  [ ScalaTest-run:5676 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5676 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:53:11  [ ScalaTest-run:5676 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5676 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:53:11  [ ScalaTest-run:5677 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5677 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:53:11  [ ScalaTest-run:5677 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5677 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:53:11  [ ScalaTest-run:5678 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5678 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:53:11  [ ScalaTest-run:5678 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5679 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:53:11  [ ScalaTest-run:5679 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5679 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:53:11  [ ScalaTest-run:5679 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5680 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:53:11  [ ScalaTest-run:5680 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:53:11  [ ScalaTest-run:5681 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:53:11  [ ScalaTest-run:5735 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:53:11  [ ScalaTest-run:5736 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:53:11  [ ScalaTest-run:5752 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:53:11  [ ScalaTest-run:5752 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:53:11  [ ScalaTest-run:5757 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:53:12  [ ScalaTest-run:6227 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:53:12  [ ScalaTest-run:6297 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61368.
2016-09-27 10:53:12  [ ScalaTest-run:6301 ] - [ INFO ]  Server created on 61368
2016-09-27 10:53:12  [ ScalaTest-run:6309 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:53:12  [ dispatcher-event-loop-2:6320 ] - [ INFO ]  Registering block manager localhost:61368 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61368)
2016-09-27 10:53:12  [ ScalaTest-run:6329 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:53:13  [ ScalaTest-run-running-RDDSuite:7900 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:53:15  [ ScalaTest-run-running-RDDSuite:9430 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:53:15  [ ScalaTest-run-running-RDDSuite:9555 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:53:15  [ dispatcher-event-loop-0:9633 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61368 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:53:15  [ ScalaTest-run-running-RDDSuite:9740 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:53:16  [ ScalaTest-run-running-RDDSuite:10201 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:53:17  [ ScalaTest-run-running-RDDSuite:11974 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:53:19  [ ScalaTest-run-running-RDDSuite:13490 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:53:20  [ ScalaTest-run-running-RDDSuite:14300 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:54:00  [ dag-scheduler-event-loop:54377 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 10:54:00  [ dag-scheduler-event-loop:54383 ] - [ INFO ]  Registering RDD 5 (map at RDDSuite.scala:262)
2016-09-27 10:55:04  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:55:05  [ ScalaTest-run:1181 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:55:06  [ ScalaTest-run:1888 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:55:06  [ ScalaTest-run:1890 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:55:06  [ ScalaTest-run:1892 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:55:07  [ ScalaTest-run:3636 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 61415.
2016-09-27 10:55:08  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4380 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:55:08  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4515 ] - [ INFO ]  Starting remoting
2016-09-27 10:55:09  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4991 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61428]
2016-09-27 10:55:09  [ ScalaTest-run:5016 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61428.
2016-09-27 10:55:09  [ ScalaTest-run:5074 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:55:09  [ ScalaTest-run:5159 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:55:09  [ ScalaTest-run:5200 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-e77fa55a-85bd-4ac4-a977-d5b4ba74c1e1
2016-09-27 10:55:09  [ ScalaTest-run:5310 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:55:09  [ ScalaTest-run:5522 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:55:10  [ ScalaTest-run:5953 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:55:10  [ ScalaTest-run:6001 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:55:10  [ ScalaTest-run:6005 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@58fbd02e: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:55:10  [ ScalaTest-run:6009 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:55:10  [ ScalaTest-run:6010 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:55:10  [ ScalaTest-run:6010 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:55:10  [ ScalaTest-run:6010 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:55:10  [ ScalaTest-run:6010 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6010 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:55:10  [ ScalaTest-run:6011 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6011 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:55:10  [ ScalaTest-run:6011 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6011 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:55:10  [ ScalaTest-run:6011 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6011 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:55:10  [ ScalaTest-run:6012 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6012 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:55:10  [ ScalaTest-run:6012 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6013 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:55:10  [ ScalaTest-run:6013 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6013 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:55:10  [ ScalaTest-run:6014 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6014 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:55:10  [ ScalaTest-run:6014 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6015 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:55:10  [ ScalaTest-run:6015 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:55:10  [ ScalaTest-run:6015 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:55:10  [ ScalaTest-run:6069 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:55:10  [ ScalaTest-run:6070 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:55:10  [ ScalaTest-run:6088 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:55:10  [ ScalaTest-run:6089 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:55:10  [ ScalaTest-run:6094 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:55:10  [ ScalaTest-run:6670 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:55:10  [ ScalaTest-run:6740 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61450.
2016-09-27 10:55:10  [ ScalaTest-run:6742 ] - [ INFO ]  Server created on 61450
2016-09-27 10:55:10  [ ScalaTest-run:6745 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:55:10  [ dispatcher-event-loop-2:6751 ] - [ INFO ]  Registering block manager localhost:61450 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61450)
2016-09-27 10:55:10  [ ScalaTest-run:6756 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:55:11  [ ScalaTest-run-running-RDDSuite:7540 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:55:12  [ ScalaTest-run-running-RDDSuite:8380 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:55:12  [ ScalaTest-run-running-RDDSuite:8447 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:55:12  [ dispatcher-event-loop-0:8454 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61450 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:55:12  [ ScalaTest-run-running-RDDSuite:8517 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:55:12  [ ScalaTest-run-running-RDDSuite:8766 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:55:14  [ ScalaTest-run-running-RDDSuite:10487 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:55:16  [ ScalaTest-run-running-RDDSuite:12124 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:55:16  [ ScalaTest-run-running-RDDSuite:12869 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:55:25  [ dag-scheduler-event-loop:21052 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 10:55:25  [ dag-scheduler-event-loop:21055 ] - [ INFO ]  Registering RDD 5 (map at RDDSuite.scala:262)
2016-09-27 10:56:03  [ ScalaTest-run:1 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 10:56:04  [ ScalaTest-run:1242 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 10:56:04  [ ScalaTest-run:1671 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 10:56:04  [ ScalaTest-run:1674 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 10:56:04  [ ScalaTest-run:1677 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 10:56:07  [ ScalaTest-run:4177 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 61486.
2016-09-27 10:56:08  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:5333 ] - [ INFO ]  Slf4jLogger started
2016-09-27 10:56:08  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:5535 ] - [ INFO ]  Starting remoting
2016-09-27 10:56:09  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:6119 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61499]
2016-09-27 10:56:09  [ ScalaTest-run:6133 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61499.
2016-09-27 10:56:09  [ ScalaTest-run:6195 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 10:56:09  [ ScalaTest-run:6295 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 10:56:09  [ ScalaTest-run:6348 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-840570f4-6ce8-4a34-bd86-14e3cd612ff0
2016-09-27 10:56:09  [ ScalaTest-run:6433 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 10:56:09  [ ScalaTest-run:6673 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 10:56:10  [ ScalaTest-run:7297 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:56:10  [ ScalaTest-run:7377 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:56:10  [ ScalaTest-run:7384 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@350ec690: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:56:10  [ ScalaTest-run:7460 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 10:56:10  [ ScalaTest-run:7460 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 10:56:10  [ ScalaTest-run:7460 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 10:56:10  [ ScalaTest-run:7461 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 10:56:10  [ ScalaTest-run:7461 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7461 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 10:56:10  [ ScalaTest-run:7461 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7462 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 10:56:10  [ ScalaTest-run:7462 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7462 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 10:56:10  [ ScalaTest-run:7462 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7463 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 10:56:10  [ ScalaTest-run:7463 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7463 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 10:56:10  [ ScalaTest-run:7463 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7463 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 10:56:10  [ ScalaTest-run:7464 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7464 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 10:56:10  [ ScalaTest-run:7464 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7465 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 10:56:10  [ ScalaTest-run:7465 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7465 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 10:56:10  [ ScalaTest-run:7466 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 10:56:10  [ ScalaTest-run:7466 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 10:56:10  [ ScalaTest-run:7522 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 10:56:10  [ ScalaTest-run:7524 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 10:56:10  [ ScalaTest-run:7554 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 10:56:10  [ ScalaTest-run:7555 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 10:56:10  [ ScalaTest-run:7564 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 10:56:11  [ ScalaTest-run:8153 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 10:56:11  [ ScalaTest-run:8243 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61518.
2016-09-27 10:56:11  [ ScalaTest-run:8246 ] - [ INFO ]  Server created on 61518
2016-09-27 10:56:11  [ ScalaTest-run:8253 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 10:56:11  [ dispatcher-event-loop-2:8265 ] - [ INFO ]  Registering block manager localhost:61518 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61518)
2016-09-27 10:56:11  [ ScalaTest-run:8275 ] - [ INFO ]  Registered BlockManager
2016-09-27 10:56:13  [ ScalaTest-run-running-RDDSuite:9793 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 10:56:14  [ ScalaTest-run-running-RDDSuite:11309 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 10:56:14  [ ScalaTest-run-running-RDDSuite:11610 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 10:56:14  [ dispatcher-event-loop-0:11621 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61518 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 10:56:15  [ ScalaTest-run-running-RDDSuite:11718 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 10:56:15  [ ScalaTest-run-running-RDDSuite:12149 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:265)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 10:56:17  [ ScalaTest-run-running-RDDSuite:13859 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 10:56:18  [ ScalaTest-run-running-RDDSuite:15403 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 10:56:19  [ ScalaTest-run-running-RDDSuite:16224 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:264
2016-09-27 10:56:21  [ dag-scheduler-event-loop:18639 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 10:56:21  [ dag-scheduler-event-loop:18643 ] - [ INFO ]  Registering RDD 5 (map at RDDSuite.scala:262)
2016-09-27 11:28:36  [ driver-heartbeater:5784821 ] - [ WARN ]  Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@10a46b8d,BlockManagerId(driver, localhost, 60134))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:449)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1765)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:470)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:107)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:107)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2016-09-27 11:28:36  [ dispatcher-event-loop-1:5784965 ] - [ WARN ]  Ignored message: HeartbeatResponse(true)
2016-09-27 11:28:37  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 11:28:38  [ ScalaTest-run:1004 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 11:28:38  [ ScalaTest-run:1489 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 11:28:38  [ ScalaTest-run:1491 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 11:28:38  [ ScalaTest-run:1493 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 11:28:40  [ ScalaTest-run:2901 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 61843.
2016-09-27 11:28:41  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:3686 ] - [ INFO ]  Slf4jLogger started
2016-09-27 11:28:41  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:3828 ] - [ INFO ]  Starting remoting
2016-09-27 11:28:41  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:4234 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:61856]
2016-09-27 11:28:41  [ ScalaTest-run:4242 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 61856.
2016-09-27 11:28:41  [ ScalaTest-run:4291 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 11:28:41  [ ScalaTest-run:4376 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 11:28:41  [ ScalaTest-run:4416 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-54af4e82-61e4-429a-9d12-71164871617b
2016-09-27 11:28:41  [ ScalaTest-run:4488 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 11:28:42  [ ScalaTest-run:4696 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 11:28:42  [ ScalaTest-run:5319 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 11:28:42  [ ScalaTest-run:5372 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:28:42  [ ScalaTest-run:5377 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@3664f108: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:28:42  [ ScalaTest-run:5381 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 11:28:42  [ ScalaTest-run:5382 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 11:28:42  [ ScalaTest-run:5382 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 11:28:42  [ ScalaTest-run:5382 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 11:28:42  [ ScalaTest-run:5382 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5382 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 11:28:42  [ ScalaTest-run:5383 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5383 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 11:28:42  [ ScalaTest-run:5383 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5383 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 11:28:42  [ ScalaTest-run:5383 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5384 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 11:28:42  [ ScalaTest-run:5384 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5384 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 11:28:42  [ ScalaTest-run:5384 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5384 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 11:28:42  [ ScalaTest-run:5384 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5385 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 11:28:42  [ ScalaTest-run:5385 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5385 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 11:28:42  [ ScalaTest-run:5385 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5386 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 11:28:42  [ ScalaTest-run:5386 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 11:28:42  [ ScalaTest-run:5386 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 11:28:42  [ ScalaTest-run:5440 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 11:28:42  [ ScalaTest-run:5441 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 11:28:42  [ ScalaTest-run:5458 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4041
2016-09-27 11:28:42  [ ScalaTest-run:5459 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4041.
2016-09-27 11:28:42  [ ScalaTest-run:5465 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4041
2016-09-27 11:28:43  [ ScalaTest-run:6255 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 11:28:43  [ ScalaTest-run:6333 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61875.
2016-09-27 11:28:43  [ ScalaTest-run:6335 ] - [ INFO ]  Server created on 61875
2016-09-27 11:28:43  [ ScalaTest-run:6338 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 11:28:43  [ dispatcher-event-loop-2:6345 ] - [ INFO ]  Registering block manager localhost:61875 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 61875)
2016-09-27 11:28:43  [ ScalaTest-run:6350 ] - [ INFO ]  Registered BlockManager
2016-09-27 11:28:44  [ ScalaTest-run-running-RDDSuite:7465 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 11:28:47  [ ScalaTest-run-running-RDDSuite:9646 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 11:28:47  [ ScalaTest-run-running-RDDSuite:9768 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 11:28:47  [ dispatcher-event-loop-0:9781 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:61875 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 11:28:47  [ ScalaTest-run-running-RDDSuite:10041 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 11:28:48  [ ScalaTest-run-running-RDDSuite:10590 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:267)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:267)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:28:49  [ ScalaTest-run-running-RDDSuite:12312 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 11:28:51  [ ScalaTest-run-running-RDDSuite:14053 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 11:28:52  [ ScalaTest-run-running-RDDSuite:15094 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:266
2016-09-27 11:30:10  [ heartbeat-receiver-event-loop-thread:93512 ] - [ WARN ]  Ignored message: HeartbeatResponse(false)
2016-09-27 11:30:10  [ driver-heartbeater:93513 ] - [ WARN ]  Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@75a578ea,BlockManagerId(driver, localhost, 61875))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:449)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:470)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1765)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:470)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:107)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:107)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2016-09-27 11:54:26  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 11:54:26  [ ScalaTest-run:904 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 11:54:27  [ ScalaTest-run:1376 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 11:54:27  [ ScalaTest-run:1377 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 11:54:27  [ ScalaTest-run:1378 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 11:54:28  [ ScalaTest-run:2700 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 62317.
2016-09-27 11:54:29  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3625 ] - [ INFO ]  Slf4jLogger started
2016-09-27 11:54:29  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3860 ] - [ INFO ]  Starting remoting
2016-09-27 11:54:30  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4621 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:62330]
2016-09-27 11:54:30  [ ScalaTest-run:4650 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 62330.
2016-09-27 11:54:30  [ ScalaTest-run:4728 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 11:54:30  [ ScalaTest-run:4838 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 11:54:30  [ ScalaTest-run:4899 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-5917186f-bc71-43f0-a189-c18e739ef278
2016-09-27 11:54:31  [ ScalaTest-run:4993 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 11:54:31  [ ScalaTest-run:5354 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 11:54:32  [ ScalaTest-run:6030 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 11:54:32  [ ScalaTest-run:6108 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:54:32  [ ScalaTest-run:6116 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@2cd4e16a: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:54:32  [ ScalaTest-run:6125 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 11:54:32  [ ScalaTest-run:6125 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 11:54:32  [ ScalaTest-run:6126 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 11:54:32  [ ScalaTest-run:6126 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 11:54:32  [ ScalaTest-run:6126 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6127 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 11:54:32  [ ScalaTest-run:6127 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6128 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 11:54:32  [ ScalaTest-run:6128 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6128 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 11:54:32  [ ScalaTest-run:6129 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6129 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 11:54:32  [ ScalaTest-run:6129 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6130 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 11:54:32  [ ScalaTest-run:6130 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6131 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 11:54:32  [ ScalaTest-run:6131 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6132 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 11:54:32  [ ScalaTest-run:6132 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6133 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 11:54:32  [ ScalaTest-run:6133 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6133 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 11:54:32  [ ScalaTest-run:6134 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6134 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 11:54:32  [ ScalaTest-run:6191 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-09-27 11:54:32  [ ScalaTest-run:6193 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 11:54:32  [ ScalaTest-run:6206 ] - [ WARN ]  FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:54:32  [ ScalaTest-run:6209 ] - [ WARN ]  FAILED org.eclipse.jetty.server.Server@7b3cde6f: java.net.BindException: Address already in use: bind
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.Net.bind(Net.java:428)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.eclipse.jetty.server.Server.doStart(Server.java:293)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:252)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1988)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1979)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:481)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:147)
	at ning.spark.suite.SharedSparkContext$class.beforeAll(SharedSparkContext.scala:21)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.beforeAll(BeforeAndAfterAll.scala:187)
	at ning.spark.suite.RDDSuite.beforeAll(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:253)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:54:32  [ ScalaTest-run:6213 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 11:54:32  [ ScalaTest-run:6213 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 11:54:32  [ ScalaTest-run:6214 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 11:54:32  [ ScalaTest-run:6214 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 11:54:32  [ ScalaTest-run:6214 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6214 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 11:54:32  [ ScalaTest-run:6215 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6215 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 11:54:32  [ ScalaTest-run:6215 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6216 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 11:54:32  [ ScalaTest-run:6216 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6217 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 11:54:32  [ ScalaTest-run:6217 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6217 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 11:54:32  [ ScalaTest-run:6218 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6218 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 11:54:32  [ ScalaTest-run:6219 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6219 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 11:54:32  [ ScalaTest-run:6219 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6220 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 11:54:32  [ ScalaTest-run:6220 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6220 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 11:54:32  [ ScalaTest-run:6221 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 11:54:32  [ ScalaTest-run:6221 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 11:54:32  [ ScalaTest-run:6275 ] - [ WARN ]  Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2016-09-27 11:54:32  [ ScalaTest-run:6277 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 11:54:32  [ ScalaTest-run:6306 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4042
2016-09-27 11:54:32  [ ScalaTest-run:6307 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4042.
2016-09-27 11:54:32  [ ScalaTest-run:6317 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4042
2016-09-27 11:54:33  [ ScalaTest-run:7088 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 11:54:33  [ ScalaTest-run:7218 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62349.
2016-09-27 11:54:33  [ ScalaTest-run:7222 ] - [ INFO ]  Server created on 62349
2016-09-27 11:54:33  [ ScalaTest-run:7230 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 11:54:33  [ dispatcher-event-loop-2:7246 ] - [ INFO ]  Registering block manager localhost:62349 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 62349)
2016-09-27 11:54:33  [ ScalaTest-run:7255 ] - [ INFO ]  Registered BlockManager
2016-09-27 11:54:34  [ ScalaTest-run-running-RDDSuite:8839 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 11:54:36  [ ScalaTest-run-running-RDDSuite:10392 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 11:54:36  [ ScalaTest-run-running-RDDSuite:10523 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 11:54:36  [ dispatcher-event-loop-0:10562 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:62349 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 11:54:36  [ ScalaTest-run-running-RDDSuite:10674 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 11:54:37  [ ScalaTest-run-running-RDDSuite:11292 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:267)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:267)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 11:54:39  [ ScalaTest-run-running-RDDSuite:13058 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 11:54:40  [ ScalaTest-run-running-RDDSuite:14694 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 11:54:41  [ ScalaTest-run-running-RDDSuite:15676 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:266
2016-09-27 11:54:47  [ dag-scheduler-event-loop:21778 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 11:54:47  [ dag-scheduler-event-loop:21782 ] - [ INFO ]  Registering RDD 5 (map at RDDSuite.scala:262)
2016-09-27 11:54:47  [ dag-scheduler-event-loop:21783 ] - [ INFO ]  Registering RDD 7 (map at RDDSuite.scala:264)
2016-09-27 15:48:05  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 15:48:06  [ ScalaTest-run:902 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 15:48:06  [ ScalaTest-run:1127 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 15:48:06  [ ScalaTest-run:1128 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 15:48:06  [ ScalaTest-run:1130 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 15:48:07  [ ScalaTest-run:2245 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 50968.
2016-09-27 15:48:08  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3538 ] - [ INFO ]  Slf4jLogger started
2016-09-27 15:48:09  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:3705 ] - [ INFO ]  Starting remoting
2016-09-27 15:48:09  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:4264 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:50981]
2016-09-27 15:48:09  [ ScalaTest-run:4280 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 50981.
2016-09-27 15:48:09  [ ScalaTest-run:4345 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 15:48:09  [ ScalaTest-run:4450 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 15:48:09  [ ScalaTest-run:4505 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-b097e23a-9356-4c25-9fbb-627ab74c5fbd
2016-09-27 15:48:09  [ ScalaTest-run:4588 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 15:48:10  [ ScalaTest-run:4846 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 15:48:10  [ ScalaTest-run:5554 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 15:48:11  [ ScalaTest-run:5669 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4040
2016-09-27 15:48:11  [ ScalaTest-run:5670 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2016-09-27 15:48:11  [ ScalaTest-run:5680 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4040
2016-09-27 15:48:11  [ ScalaTest-run:6018 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 15:48:11  [ ScalaTest-run:6188 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51000.
2016-09-27 15:48:11  [ ScalaTest-run:6191 ] - [ INFO ]  Server created on 51000
2016-09-27 15:48:11  [ ScalaTest-run:6198 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 15:48:11  [ dispatcher-event-loop-2:6207 ] - [ INFO ]  Registering block manager localhost:51000 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 51000)
2016-09-27 15:48:11  [ ScalaTest-run:6215 ] - [ INFO ]  Registered BlockManager
2016-09-27 15:48:12  [ ScalaTest-run-running-RDDSuite:6960 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 15:48:14  [ ScalaTest-run-running-RDDSuite:8872 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 15:48:17  [ ScalaTest-run-running-RDDSuite:11875 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 127.1 KB)
2016-09-27 15:48:17  [ ScalaTest-run-running-RDDSuite:11983 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.8 KB, free 140.9 KB)
2016-09-27 15:48:17  [ dispatcher-event-loop-0:11996 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:51000 (size: 13.8 KB, free: 1117.9 MB)
2016-09-27 15:48:17  [ ScalaTest-run-running-RDDSuite:12012 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:269
2016-09-27 15:48:17  [ ScalaTest-run-running-RDDSuite:12400 ] - [ INFO ]  

===== FINISHED ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 15:48:17  [ ScalaTest-run:12442 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12443 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 15:48:17  [ ScalaTest-run:12443 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 15:48:17  [ ScalaTest-run:12444 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 15:48:17  [ ScalaTest-run:12444 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 15:48:17  [ ScalaTest-run:12444 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12445 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 15:48:17  [ ScalaTest-run:12445 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12445 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 15:48:17  [ ScalaTest-run:12446 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12446 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 15:48:17  [ ScalaTest-run:12446 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12446 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 15:48:17  [ ScalaTest-run:12447 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12447 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 15:48:17  [ ScalaTest-run:12448 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12448 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 15:48:17  [ ScalaTest-run:12448 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12449 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 15:48:17  [ ScalaTest-run:12449 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12449 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 15:48:17  [ ScalaTest-run:12450 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12451 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 15:48:17  [ ScalaTest-run:12451 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 15:48:17  [ ScalaTest-run:12452 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 15:48:17  [ ScalaTest-run:12509 ] - [ INFO ]  Stopped Spark web UI at http://192.168.199.144:4040
2016-09-27 15:48:17  [ dispatcher-event-loop-3:12569 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2016-09-27 15:48:18  [ ScalaTest-run:12616 ] - [ INFO ]  MemoryStore cleared
2016-09-27 15:48:18  [ ScalaTest-run:12618 ] - [ INFO ]  BlockManager stopped
2016-09-27 15:48:18  [ ScalaTest-run:12697 ] - [ INFO ]  BlockManagerMaster stopped
2016-09-27 15:48:18  [ dispatcher-event-loop-0:12724 ] - [ INFO ]  OutputCommitCoordinator stopped!
2016-09-27 15:48:18  [ ScalaTest-run:12744 ] - [ INFO ]  Successfully stopped SparkContext
2016-09-27 15:48:18  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:12784 ] - [ INFO ]  Shutting down remote daemon.
2016-09-27 15:48:18  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:12810 ] - [ INFO ]  Remote daemon shut down; proceeding with flushing remote transports.
2016-09-27 15:48:18  [ Thread-3:12817 ] - [ INFO ]  Shutdown hook called
2016-09-27 15:48:18  [ Thread-3:12822 ] - [ INFO ]  Deleting directory C:\Users\ning\AppData\Local\Temp\spark-7bd3f4fb-81af-48b9-985f-f0665a6150d0
2016-09-27 16:09:50  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 16:09:51  [ ScalaTest-run:1153 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 16:09:51  [ ScalaTest-run:1348 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 16:09:51  [ ScalaTest-run:1349 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 16:09:51  [ ScalaTest-run:1350 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 16:09:53  [ ScalaTest-run:2608 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 51265.
2016-09-27 16:09:53  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:3287 ] - [ INFO ]  Slf4jLogger started
2016-09-27 16:09:54  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:3488 ] - [ INFO ]  Starting remoting
2016-09-27 16:09:54  [ ScalaTest-run:4166 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 51296.
2016-09-27 16:09:54  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:4185 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:51296]
2016-09-27 16:09:54  [ ScalaTest-run:4214 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 16:09:54  [ ScalaTest-run:4327 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 16:09:55  [ ScalaTest-run:4672 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-2620c0bb-1166-4798-8407-eb0aa9359dbe
2016-09-27 16:09:55  [ ScalaTest-run:4767 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 16:09:55  [ ScalaTest-run:5056 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 16:09:56  [ ScalaTest-run:5713 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 16:09:56  [ ScalaTest-run:5783 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4040
2016-09-27 16:09:56  [ ScalaTest-run:5784 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2016-09-27 16:09:56  [ ScalaTest-run:5790 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4040
2016-09-27 16:09:56  [ ScalaTest-run:5999 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 16:09:56  [ ScalaTest-run:6050 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51317.
2016-09-27 16:09:56  [ ScalaTest-run:6053 ] - [ INFO ]  Server created on 51317
2016-09-27 16:09:56  [ ScalaTest-run:6058 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 16:09:56  [ dispatcher-event-loop-2:6066 ] - [ INFO ]  Registering block manager localhost:51317 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 51317)
2016-09-27 16:09:56  [ ScalaTest-run:6071 ] - [ INFO ]  Registered BlockManager
2016-09-27 16:09:57  [ ScalaTest-run-running-RDDSuite:6671 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 16:09:58  [ ScalaTest-run-running-RDDSuite:8405 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 16:10:02  [ ScalaTest-run-running-RDDSuite:12131 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 127.1 KB)
2016-09-27 16:10:02  [ ScalaTest-run-running-RDDSuite:12276 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.8 KB, free 140.9 KB)
2016-09-27 16:10:02  [ dispatcher-event-loop-0:12292 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:51317 (size: 13.8 KB, free: 1117.9 MB)
2016-09-27 16:10:02  [ ScalaTest-run-running-RDDSuite:12308 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:269
2016-09-27 16:10:03  [ ScalaTest-run-running-RDDSuite:12634 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:273)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:257)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:257)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)
2016-09-27 16:10:03  [ ScalaTest-run-running-RDDSuite:12685 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 16:10:03  [ ScalaTest-run-running-RDDSuite:12817 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:273
2016-09-27 16:10:03  [ dag-scheduler-event-loop:12917 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:272)
2016-09-27 16:10:03  [ dag-scheduler-event-loop:12927 ] - [ INFO ]  Got job 0 (collect at RDDSuite.scala:273) with 3 output partitions
2016-09-27 16:10:03  [ dag-scheduler-event-loop:12929 ] - [ INFO ]  Final stage: ResultStage 1 (collect at RDDSuite.scala:273)
2016-09-27 16:10:03  [ dag-scheduler-event-loop:12932 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2016-09-27 16:10:03  [ dag-scheduler-event-loop:12938 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2016-09-27 16:10:03  [ dag-scheduler-event-loop:12962 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at RDDSuite.scala:272), which has no missing parents
2016-09-27 16:10:04  [ dag-scheduler-event-loop:13589 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.4 KB, free 146.2 KB)
2016-09-27 16:10:04  [ dag-scheduler-event-loop:13595 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 149.2 KB)
2016-09-27 16:10:04  [ dispatcher-event-loop-1:13597 ] - [ INFO ]  Added broadcast_1_piece0 in memory on localhost:51317 (size: 3.0 KB, free: 1117.9 MB)
2016-09-27 16:10:04  [ dag-scheduler-event-loop:13599 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-09-27 16:10:04  [ dag-scheduler-event-loop:13606 ] - [ INFO ]  Submitting 3 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at RDDSuite.scala:272)
2016-09-27 16:10:04  [ dag-scheduler-event-loop:13624 ] - [ INFO ]  Adding task set 0.0 with 3 tasks
2016-09-27 16:10:04  [ dispatcher-event-loop-2:14312 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2128 bytes)
2016-09-27 16:10:04  [ dispatcher-event-loop-2:14375 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2128 bytes)
2016-09-27 16:10:04  [ dispatcher-event-loop-2:14377 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2128 bytes)
2016-09-27 16:10:05  [ Executor task launch worker-1:14587 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2016-09-27 16:10:05  [ Executor task launch worker-2:14587 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2016-09-27 16:10:05  [ Executor task launch worker-0:14587 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2016-09-27 16:10:05  [ Executor task launch worker-0:15213 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:0+8
2016-09-27 16:10:05  [ Executor task launch worker-2:15213 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:16+1
2016-09-27 16:10:05  [ Executor task launch worker-1:15213 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:8+8
2016-09-27 16:10:05  [ Executor task launch worker-1:15385 ] - [ INFO ]  mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-27 16:10:05  [ Executor task launch worker-1:15386 ] - [ INFO ]  mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-27 16:10:05  [ Executor task launch worker-1:15386 ] - [ INFO ]  mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-27 16:10:05  [ Executor task launch worker-1:15386 ] - [ INFO ]  mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-27 16:10:05  [ Executor task launch worker-1:15387 ] - [ INFO ]  mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-27 16:10:07  [ Executor task launch worker-0:16735 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 2255 bytes result sent to driver
2016-09-27 16:10:07  [ Executor task launch worker-1:16739 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 2255 bytes result sent to driver
2016-09-27 16:10:07  [ Executor task launch worker-2:16757 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2). 2255 bytes result sent to driver
2016-09-27 16:10:07  [ task-result-getter-1:17000 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 2583 ms on localhost (1/3)
2016-09-27 16:10:07  [ task-result-getter-0:17006 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 2861 ms on localhost (2/3)
2016-09-27 16:10:07  [ task-result-getter-2:17007 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2) in 2630 ms on localhost (3/3)
2016-09-27 16:10:07  [ task-result-getter-2:17135 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-27 16:10:07  [ dag-scheduler-event-loop:17158 ] - [ INFO ]  ShuffleMapStage 0 (map at RDDSuite.scala:272) finished in 3.252 s
2016-09-27 16:10:07  [ dag-scheduler-event-loop:17162 ] - [ INFO ]  looking for newly runnable stages
2016-09-27 16:10:07  [ dag-scheduler-event-loop:17166 ] - [ INFO ]  running: Set()
2016-09-27 16:10:07  [ dag-scheduler-event-loop:17169 ] - [ INFO ]  waiting: Set(ResultStage 1)
2016-09-27 16:10:07  [ dag-scheduler-event-loop:17171 ] - [ INFO ]  failed: Set()
2016-09-27 16:10:07  [ dag-scheduler-event-loop:17241 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at RDDSuite.scala:273), which has no missing parents
2016-09-27 16:10:08  [ dag-scheduler-event-loop:17636 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 151.8 KB)
2016-09-27 16:10:08  [ dag-scheduler-event-loop:17640 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 1596.0 B, free 153.4 KB)
2016-09-27 16:10:08  [ dispatcher-event-loop-0:17647 ] - [ INFO ]  Added broadcast_2_piece0 in memory on localhost:51317 (size: 1596.0 B, free: 1117.9 MB)
2016-09-27 16:10:08  [ dag-scheduler-event-loop:17649 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-09-27 16:10:08  [ dag-scheduler-event-loop:17653 ] - [ INFO ]  Submitting 3 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at RDDSuite.scala:273)
2016-09-27 16:10:08  [ dag-scheduler-event-loop:17654 ] - [ INFO ]  Adding task set 1.0 with 3 tasks
2016-09-27 16:10:08  [ dispatcher-event-loop-2:17815 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 3, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-09-27 16:10:08  [ dispatcher-event-loop-2:17816 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 4, localhost, partition 1,NODE_LOCAL, 1894 bytes)
2016-09-27 16:10:08  [ dispatcher-event-loop-2:17818 ] - [ INFO ]  Starting task 2.0 in stage 1.0 (TID 5, localhost, partition 2,NODE_LOCAL, 1894 bytes)
2016-09-27 16:10:08  [ Executor task launch worker-0:17819 ] - [ INFO ]  Running task 2.0 in stage 1.0 (TID 5)
2016-09-27 16:10:08  [ Executor task launch worker-2:17829 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 3)
2016-09-27 16:10:08  [ Executor task launch worker-1:17832 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 4)
2016-09-27 16:10:08  [ Executor task launch worker-1:18174 ] - [ INFO ]  Getting 2 non-empty blocks out of 3 blocks
2016-09-27 16:10:08  [ Executor task launch worker-0:18174 ] - [ INFO ]  Getting 2 non-empty blocks out of 3 blocks
2016-09-27 16:10:08  [ Executor task launch worker-2:18176 ] - [ INFO ]  Getting 1 non-empty blocks out of 3 blocks
2016-09-27 16:10:09  [ Executor task launch worker-1:18435 ] - [ INFO ]  Started 0 remote fetches in 420 ms
2016-09-27 16:10:09  [ Executor task launch worker-2:18445 ] - [ INFO ]  Started 0 remote fetches in 428 ms
2016-09-27 16:10:09  [ Executor task launch worker-0:18449 ] - [ INFO ]  Started 0 remote fetches in 432 ms
2016-09-27 16:10:09  [ Executor task launch worker-2:18916 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 3). 1307 bytes result sent to driver
2016-09-27 16:10:09  [ Executor task launch worker-1:18922 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 4). 1333 bytes result sent to driver
2016-09-27 16:10:09  [ Executor task launch worker-0:18928 ] - [ INFO ]  Finished task 2.0 in stage 1.0 (TID 5). 1327 bytes result sent to driver
2016-09-27 16:10:09  [ task-result-getter-0:18948 ] - [ INFO ]  Finished task 2.0 in stage 1.0 (TID 5) in 1130 ms on localhost (1/3)
2016-09-27 16:10:09  [ task-result-getter-1:18949 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 4) in 1133 ms on localhost (2/3)
2016-09-27 16:10:09  [ task-result-getter-3:18949 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 3) in 1186 ms on localhost (3/3)
2016-09-27 16:10:09  [ task-result-getter-3:18962 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-27 16:10:09  [ dag-scheduler-event-loop:18956 ] - [ INFO ]  ResultStage 1 (collect at RDDSuite.scala:273) finished in 1.194 s
2016-09-27 16:10:09  [ ScalaTest-run-running-RDDSuite:19044 ] - [ INFO ]  Job 0 finished: collect at RDDSuite.scala:273, took 6.216847 s
2016-09-27 16:10:09  [ ScalaTest-run-running-RDDSuite:19236 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 127.2 KB, free 280.5 KB)
2016-09-27 16:10:09  [ ScalaTest-run-running-RDDSuite:19301 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.8 KB, free 294.3 KB)
2016-09-27 16:10:09  [ dispatcher-event-loop-0:19303 ] - [ INFO ]  Added broadcast_3_piece0 in memory on localhost:51317 (size: 13.8 KB, free: 1117.8 MB)
2016-09-27 16:10:09  [ ScalaTest-run-running-RDDSuite:19313 ] - [ INFO ]  Created broadcast 3 from collect at RDDSuite.scala:273
2016-09-27 16:10:09  [ ScalaTest-run-running-RDDSuite:19346 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:273
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19348 ] - [ INFO ]  Got job 1 (collect at RDDSuite.scala:273) with 3 output partitions
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19350 ] - [ INFO ]  Final stage: ResultStage 2 (collect at RDDSuite.scala:273)
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19351 ] - [ INFO ]  Parents of final stage: List()
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19351 ] - [ INFO ]  Missing parents: List()
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19352 ] - [ INFO ]  Submitting ResultStage 2 (MapPartitionsRDD[2] at flatMap at RDDSuite.scala:270), which has no missing parents
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19364 ] - [ INFO ]  Block broadcast_4 stored as values in memory (estimated size 4.5 KB, free 298.8 KB)
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19376 ] - [ INFO ]  Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 301.4 KB)
2016-09-27 16:10:09  [ dispatcher-event-loop-1:19385 ] - [ INFO ]  Added broadcast_4_piece0 in memory on localhost:51317 (size: 2.6 KB, free: 1117.8 MB)
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19386 ] - [ INFO ]  Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19387 ] - [ INFO ]  Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[2] at flatMap at RDDSuite.scala:270)
2016-09-27 16:10:09  [ dag-scheduler-event-loop:19388 ] - [ INFO ]  Adding task set 2.0 with 3 tasks
2016-09-27 16:10:09  [ dispatcher-event-loop-3:19392 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2139 bytes)
2016-09-27 16:10:09  [ dispatcher-event-loop-3:19393 ] - [ INFO ]  Starting task 1.0 in stage 2.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2139 bytes)
2016-09-27 16:10:09  [ dispatcher-event-loop-3:19395 ] - [ INFO ]  Starting task 2.0 in stage 2.0 (TID 8, localhost, partition 2,PROCESS_LOCAL, 2139 bytes)
2016-09-27 16:10:09  [ Executor task launch worker-1:19396 ] - [ INFO ]  Running task 1.0 in stage 2.0 (TID 7)
2016-09-27 16:10:09  [ Executor task launch worker-1:19404 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:8+8
2016-09-27 16:10:09  [ Executor task launch worker-0:19412 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 6)
2016-09-27 16:10:10  [ Executor task launch worker-0:19441 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:0+8
2016-09-27 16:10:10  [ Executor task launch worker-2:19475 ] - [ INFO ]  Running task 2.0 in stage 2.0 (TID 8)
2016-09-27 16:10:10  [ Executor task launch worker-2:19506 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:16+1
2016-09-27 16:10:10  [ Executor task launch worker-0:19564 ] - [ ERROR ]  Exception in task 0.0 in stage 2.0 (TID 6)
java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-27 16:10:10  [ Executor task launch worker-2:19566 ] - [ ERROR ]  Exception in task 2.0 in stage 2.0 (TID 8)
java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-27 16:10:10  [ Executor task launch worker-1:19564 ] - [ ERROR ]  Exception in task 1.0 in stage 2.0 (TID 7)
java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-27 16:10:10  [ task-result-getter-2:19694 ] - [ WARN ]  Lost task 2.0 in stage 2.0 (TID 8, localhost): java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-09-27 16:10:10  [ task-result-getter-2:19744 ] - [ ERROR ]  Task 2 in stage 2.0 failed 1 times; aborting job
2016-09-27 16:10:10  [ task-result-getter-2:19748 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-27 16:10:10  [ dag-scheduler-event-loop:19796 ] - [ INFO ]  Cancelling stage 2
2016-09-27 16:10:10  [ task-result-getter-0:19845 ] - [ INFO ]  Lost task 1.0 in stage 2.0 (TID 7) on executor localhost: java.lang.NullPointerException (null) [duplicate 1]
2016-09-27 16:10:10  [ dag-scheduler-event-loop:19845 ] - [ INFO ]  ResultStage 2 (collect at RDDSuite.scala:273) failed in 0.452 s
2016-09-27 16:10:10  [ task-result-getter-0:19849 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-27 16:10:10  [ task-result-getter-1:19850 ] - [ INFO ]  Lost task 0.0 in stage 2.0 (TID 6) on executor localhost: java.lang.NullPointerException (null) [duplicate 2]
2016-09-27 16:10:10  [ task-result-getter-1:19851 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-27 16:10:10  [ ScalaTest-run-running-RDDSuite:19851 ] - [ INFO ]  Job 1 failed: collect at RDDSuite.scala:273, took 0.504830 s
2016-09-27 16:10:10  [ ScalaTest-run-running-RDDSuite:19859 ] - [ INFO ]  

===== FINISHED ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 16:10:10  [ ScalaTest-run:19934 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19935 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 16:10:10  [ ScalaTest-run:19935 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 16:10:10  [ ScalaTest-run:19935 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 16:10:10  [ ScalaTest-run:19936 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 16:10:10  [ ScalaTest-run:19936 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19936 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 16:10:10  [ ScalaTest-run:19937 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19937 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 16:10:10  [ ScalaTest-run:19938 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19938 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 16:10:10  [ ScalaTest-run:19938 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19938 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 16:10:10  [ ScalaTest-run:19939 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19939 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 16:10:10  [ ScalaTest-run:19939 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19940 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 16:10:10  [ ScalaTest-run:19940 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19940 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 16:10:10  [ ScalaTest-run:19941 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19941 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 16:10:10  [ ScalaTest-run:19942 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19942 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 16:10:10  [ ScalaTest-run:19942 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 16:10:10  [ ScalaTest-run:19942 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 16:10:10  [ ScalaTest-run:20013 ] - [ INFO ]  Stopped Spark web UI at http://192.168.199.144:4040
2016-09-27 16:10:10  [ dispatcher-event-loop-0:20147 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2016-09-27 16:10:10  [ ScalaTest-run:20313 ] - [ INFO ]  MemoryStore cleared
2016-09-27 16:10:10  [ ScalaTest-run:20315 ] - [ INFO ]  BlockManager stopped
2016-09-27 16:10:10  [ ScalaTest-run:20320 ] - [ INFO ]  BlockManagerMaster stopped
2016-09-27 16:10:10  [ dispatcher-event-loop-0:20335 ] - [ INFO ]  OutputCommitCoordinator stopped!
2016-09-27 16:10:10  [ ScalaTest-run:20355 ] - [ INFO ]  Successfully stopped SparkContext
2016-09-27 16:10:10  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:20368 ] - [ INFO ]  Shutting down remote daemon.
2016-09-27 16:10:10  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:20375 ] - [ INFO ]  Remote daemon shut down; proceeding with flushing remote transports.
2016-09-27 16:10:10  [ Thread-3:20404 ] - [ INFO ]  Shutdown hook called
2016-09-27 16:10:10  [ Thread-3:20413 ] - [ INFO ]  Deleting directory C:\Users\ning\AppData\Local\Temp\spark-62a96ea8-b801-4f4a-a547-bb0228e886ad
2016-09-27 16:16:52  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 16:16:53  [ ScalaTest-run:784 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 16:16:53  [ ScalaTest-run:966 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 16:16:53  [ ScalaTest-run:968 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 16:16:53  [ ScalaTest-run:969 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 16:16:54  [ ScalaTest-run:2098 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 51527.
2016-09-27 16:16:55  [ sparkDriverActorSystem-akka.actor.default-dispatcher-5:2664 ] - [ INFO ]  Slf4jLogger started
2016-09-27 16:16:55  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:2756 ] - [ INFO ]  Starting remoting
2016-09-27 16:16:55  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:3067 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:51540]
2016-09-27 16:16:55  [ ScalaTest-run:3081 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 51540.
2016-09-27 16:16:55  [ ScalaTest-run:3122 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 16:16:55  [ ScalaTest-run:3221 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 16:16:55  [ ScalaTest-run:3257 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-50f50201-7c89-4567-9202-388a7604a5fa
2016-09-27 16:16:55  [ ScalaTest-run:3318 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 16:16:56  [ ScalaTest-run:3491 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 16:16:56  [ ScalaTest-run:3891 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 16:16:56  [ ScalaTest-run:3990 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4040
2016-09-27 16:16:56  [ ScalaTest-run:3990 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2016-09-27 16:16:56  [ ScalaTest-run:3999 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4040
2016-09-27 16:16:56  [ ScalaTest-run:4204 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 16:16:56  [ ScalaTest-run:4263 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51559.
2016-09-27 16:16:56  [ ScalaTest-run:4265 ] - [ INFO ]  Server created on 51559
2016-09-27 16:16:56  [ ScalaTest-run:4268 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 16:16:56  [ dispatcher-event-loop-2:4277 ] - [ INFO ]  Registering block manager localhost:51559 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 51559)
2016-09-27 16:16:56  [ ScalaTest-run:4283 ] - [ INFO ]  Registered BlockManager
2016-09-27 16:16:57  [ ScalaTest-run-running-RDDSuite:4699 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 16:16:59  [ ScalaTest-run-running-RDDSuite:6451 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 16:17:02  [ ScalaTest-run-running-RDDSuite:9418 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 127.1 KB)
2016-09-27 16:17:02  [ ScalaTest-run-running-RDDSuite:9515 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.8 KB, free 140.9 KB)
2016-09-27 16:17:02  [ dispatcher-event-loop-0:9527 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:51559 (size: 13.8 KB, free: 1117.9 MB)
2016-09-27 16:17:02  [ ScalaTest-run-running-RDDSuite:9540 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:269
2016-09-27 16:17:02  [ ScalaTest-run-running-RDDSuite:9842 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:273)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:257)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:257)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)
2016-09-27 16:17:02  [ ScalaTest-run-running-RDDSuite:9896 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 16:17:02  [ ScalaTest-run-running-RDDSuite:10033 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:273
2016-09-27 16:17:02  [ dag-scheduler-event-loop:10114 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:272)
2016-09-27 16:17:02  [ dag-scheduler-event-loop:10122 ] - [ INFO ]  Got job 0 (collect at RDDSuite.scala:273) with 3 output partitions
2016-09-27 16:17:02  [ dag-scheduler-event-loop:10124 ] - [ INFO ]  Final stage: ResultStage 1 (collect at RDDSuite.scala:273)
2016-09-27 16:17:02  [ dag-scheduler-event-loop:10126 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 0)
2016-09-27 16:17:02  [ dag-scheduler-event-loop:10137 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 0)
2016-09-27 16:17:02  [ dag-scheduler-event-loop:10169 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at RDDSuite.scala:272), which has no missing parents
2016-09-27 16:17:02  [ dag-scheduler-event-loop:10362 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 5.4 KB, free 146.2 KB)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:10371 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 149.2 KB)
2016-09-27 16:17:03  [ dispatcher-event-loop-1:10376 ] - [ INFO ]  Added broadcast_1_piece0 in memory on localhost:51559 (size: 3.0 KB, free: 1117.9 MB)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:10381 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-09-27 16:17:03  [ dag-scheduler-event-loop:10407 ] - [ INFO ]  Submitting 3 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at RDDSuite.scala:272)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:10417 ] - [ INFO ]  Adding task set 0.0 with 3 tasks
2016-09-27 16:17:03  [ dispatcher-event-loop-2:10554 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2128 bytes)
2016-09-27 16:17:03  [ dispatcher-event-loop-2:10566 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2128 bytes)
2016-09-27 16:17:03  [ dispatcher-event-loop-2:10568 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2128 bytes)
2016-09-27 16:17:03  [ Executor task launch worker-0:10597 ] - [ INFO ]  Running task 0.0 in stage 0.0 (TID 0)
2016-09-27 16:17:03  [ Executor task launch worker-1:10600 ] - [ INFO ]  Running task 1.0 in stage 0.0 (TID 1)
2016-09-27 16:17:03  [ Executor task launch worker-2:10602 ] - [ INFO ]  Running task 2.0 in stage 0.0 (TID 2)
2016-09-27 16:17:03  [ Executor task launch worker-2:10707 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:16+1
2016-09-27 16:17:03  [ Executor task launch worker-0:10709 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:0+8
2016-09-27 16:17:03  [ Executor task launch worker-1:10714 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:8+8
2016-09-27 16:17:03  [ Executor task launch worker-1:10770 ] - [ INFO ]  mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-27 16:17:03  [ Executor task launch worker-1:10770 ] - [ INFO ]  mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-27 16:17:03  [ Executor task launch worker-1:10771 ] - [ INFO ]  mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-27 16:17:03  [ Executor task launch worker-1:10771 ] - [ INFO ]  mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-27 16:17:03  [ Executor task launch worker-1:10771 ] - [ INFO ]  mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-27 16:17:03  [ Executor task launch worker-0:11000 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0). 2255 bytes result sent to driver
2016-09-27 16:17:03  [ Executor task launch worker-1:11000 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1). 2255 bytes result sent to driver
2016-09-27 16:17:03  [ Executor task launch worker-2:11000 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2). 2255 bytes result sent to driver
2016-09-27 16:17:03  [ task-result-getter-1:11028 ] - [ INFO ]  Finished task 2.0 in stage 0.0 (TID 2) in 455 ms on localhost (1/3)
2016-09-27 16:17:03  [ task-result-getter-0:11029 ] - [ INFO ]  Finished task 0.0 in stage 0.0 (TID 0) in 525 ms on localhost (2/3)
2016-09-27 16:17:03  [ task-result-getter-2:11029 ] - [ INFO ]  Finished task 1.0 in stage 0.0 (TID 1) in 465 ms on localhost (3/3)
2016-09-27 16:17:03  [ task-result-getter-2:11033 ] - [ INFO ]  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11119 ] - [ INFO ]  ShuffleMapStage 0 (map at RDDSuite.scala:272) finished in 0.655 s
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11120 ] - [ INFO ]  looking for newly runnable stages
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11122 ] - [ INFO ]  running: Set()
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11124 ] - [ INFO ]  waiting: Set(ResultStage 1)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11127 ] - [ INFO ]  failed: Set()
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11131 ] - [ INFO ]  Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at RDDSuite.scala:273), which has no missing parents
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11153 ] - [ INFO ]  Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 151.8 KB)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11162 ] - [ INFO ]  Block broadcast_2_piece0 stored as bytes in memory (estimated size 1596.0 B, free 153.4 KB)
2016-09-27 16:17:03  [ dispatcher-event-loop-1:11168 ] - [ INFO ]  Added broadcast_2_piece0 in memory on localhost:51559 (size: 1596.0 B, free: 1117.9 MB)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11169 ] - [ INFO ]  Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11172 ] - [ INFO ]  Submitting 3 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at RDDSuite.scala:273)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11173 ] - [ INFO ]  Adding task set 1.0 with 3 tasks
2016-09-27 16:17:03  [ dispatcher-event-loop-0:11193 ] - [ INFO ]  Starting task 0.0 in stage 1.0 (TID 3, localhost, partition 0,NODE_LOCAL, 1894 bytes)
2016-09-27 16:17:03  [ dispatcher-event-loop-0:11195 ] - [ INFO ]  Starting task 1.0 in stage 1.0 (TID 4, localhost, partition 1,NODE_LOCAL, 1894 bytes)
2016-09-27 16:17:03  [ dispatcher-event-loop-0:11196 ] - [ INFO ]  Starting task 2.0 in stage 1.0 (TID 5, localhost, partition 2,NODE_LOCAL, 1894 bytes)
2016-09-27 16:17:03  [ Executor task launch worker-1:11197 ] - [ INFO ]  Running task 1.0 in stage 1.0 (TID 4)
2016-09-27 16:17:03  [ Executor task launch worker-0:11197 ] - [ INFO ]  Running task 2.0 in stage 1.0 (TID 5)
2016-09-27 16:17:03  [ Executor task launch worker-2:11199 ] - [ INFO ]  Running task 0.0 in stage 1.0 (TID 3)
2016-09-27 16:17:03  [ Executor task launch worker-2:11266 ] - [ INFO ]  Getting 1 non-empty blocks out of 3 blocks
2016-09-27 16:17:03  [ Executor task launch worker-1:11266 ] - [ INFO ]  Getting 2 non-empty blocks out of 3 blocks
2016-09-27 16:17:03  [ Executor task launch worker-0:11271 ] - [ INFO ]  Getting 2 non-empty blocks out of 3 blocks
2016-09-27 16:17:03  [ Executor task launch worker-2:11274 ] - [ INFO ]  Started 0 remote fetches in 45 ms
2016-09-27 16:17:03  [ Executor task launch worker-0:11281 ] - [ INFO ]  Started 0 remote fetches in 48 ms
2016-09-27 16:17:03  [ Executor task launch worker-1:11287 ] - [ INFO ]  Started 0 remote fetches in 60 ms
2016-09-27 16:17:03  [ Executor task launch worker-2:11352 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 3). 1307 bytes result sent to driver
2016-09-27 16:17:03  [ Executor task launch worker-1:11352 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 4). 1333 bytes result sent to driver
2016-09-27 16:17:03  [ Executor task launch worker-0:11352 ] - [ INFO ]  Finished task 2.0 in stage 1.0 (TID 5). 1327 bytes result sent to driver
2016-09-27 16:17:03  [ task-result-getter-3:11356 ] - [ INFO ]  Finished task 0.0 in stage 1.0 (TID 3) in 170 ms on localhost (1/3)
2016-09-27 16:17:03  [ task-result-getter-1:11357 ] - [ INFO ]  Finished task 1.0 in stage 1.0 (TID 4) in 163 ms on localhost (2/3)
2016-09-27 16:17:03  [ task-result-getter-0:11358 ] - [ INFO ]  Finished task 2.0 in stage 1.0 (TID 5) in 162 ms on localhost (3/3)
2016-09-27 16:17:03  [ dag-scheduler-event-loop:11358 ] - [ INFO ]  ResultStage 1 (collect at RDDSuite.scala:273) finished in 0.172 s
2016-09-27 16:17:03  [ task-result-getter-0:11358 ] - [ INFO ]  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-27 16:17:04  [ ScalaTest-run-running-RDDSuite:11380 ] - [ INFO ]  Job 0 finished: collect at RDDSuite.scala:273, took 1.346234 s
2016-09-27 16:17:04  [ ScalaTest-run-running-RDDSuite:11406 ] - [ INFO ]  Block broadcast_3 stored as values in memory (estimated size 127.2 KB, free 280.5 KB)
2016-09-27 16:17:04  [ ScalaTest-run-running-RDDSuite:11449 ] - [ INFO ]  Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.8 KB, free 294.3 KB)
2016-09-27 16:17:04  [ dispatcher-event-loop-1:11452 ] - [ INFO ]  Added broadcast_3_piece0 in memory on localhost:51559 (size: 13.8 KB, free: 1117.8 MB)
2016-09-27 16:17:04  [ ScalaTest-run-running-RDDSuite:11456 ] - [ INFO ]  Created broadcast 3 from collect at RDDSuite.scala:273
2016-09-27 16:17:04  [ ScalaTest-run-running-RDDSuite:11469 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:273
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11473 ] - [ INFO ]  Got job 1 (collect at RDDSuite.scala:273) with 3 output partitions
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11473 ] - [ INFO ]  Final stage: ResultStage 2 (collect at RDDSuite.scala:273)
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11473 ] - [ INFO ]  Parents of final stage: List()
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11474 ] - [ INFO ]  Missing parents: List()
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11475 ] - [ INFO ]  Submitting ResultStage 2 (MapPartitionsRDD[2] at flatMap at RDDSuite.scala:270), which has no missing parents
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11480 ] - [ INFO ]  Block broadcast_4 stored as values in memory (estimated size 4.5 KB, free 298.8 KB)
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11491 ] - [ INFO ]  Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 301.4 KB)
2016-09-27 16:17:04  [ dispatcher-event-loop-3:11492 ] - [ INFO ]  Added broadcast_4_piece0 in memory on localhost:51559 (size: 2.6 KB, free: 1117.8 MB)
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11495 ] - [ INFO ]  Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11496 ] - [ INFO ]  Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[2] at flatMap at RDDSuite.scala:270)
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11496 ] - [ INFO ]  Adding task set 2.0 with 3 tasks
2016-09-27 16:17:04  [ dispatcher-event-loop-2:11500 ] - [ INFO ]  Starting task 0.0 in stage 2.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2139 bytes)
2016-09-27 16:17:04  [ dispatcher-event-loop-2:11501 ] - [ INFO ]  Starting task 1.0 in stage 2.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2139 bytes)
2016-09-27 16:17:04  [ dispatcher-event-loop-2:11502 ] - [ INFO ]  Starting task 2.0 in stage 2.0 (TID 8, localhost, partition 2,PROCESS_LOCAL, 2139 bytes)
2016-09-27 16:17:04  [ Executor task launch worker-1:11503 ] - [ INFO ]  Running task 1.0 in stage 2.0 (TID 7)
2016-09-27 16:17:04  [ Executor task launch worker-1:11511 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:8+8
2016-09-27 16:17:04  [ Executor task launch worker-0:11533 ] - [ INFO ]  Running task 0.0 in stage 2.0 (TID 6)
2016-09-27 16:17:04  [ Executor task launch worker-1:11561 ] - [ ERROR ]  Exception in task 1.0 in stage 2.0 (TID 7)
java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-27 16:17:04  [ Executor task launch worker-2:11576 ] - [ INFO ]  Running task 2.0 in stage 2.0 (TID 8)
2016-09-27 16:17:04  [ Executor task launch worker-2:11599 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:16+1
2016-09-27 16:17:04  [ task-result-getter-2:11606 ] - [ WARN ]  Lost task 1.0 in stage 2.0 (TID 7, localhost): java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-09-27 16:17:04  [ task-result-getter-2:11616 ] - [ ERROR ]  Task 1 in stage 2.0 failed 1 times; aborting job
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11639 ] - [ INFO ]  Cancelling stage 2
2016-09-27 16:17:04  [ Executor task launch worker-0:11649 ] - [ INFO ]  Input split: file:/D:/test/111111111/111111111.log:0+8
2016-09-27 16:17:04  [ Executor task launch worker-2:11672 ] - [ ERROR ]  Exception in task 2.0 in stage 2.0 (TID 8)
java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-27 16:17:04  [ Executor task launch worker-0:11685 ] - [ ERROR ]  Exception in task 0.0 in stage 2.0 (TID 6)
java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1012)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:404)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:678)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:661)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:639)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:468)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:424)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:905)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:886)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:848)
	at org.apache.spark.rdd.ReliableCheckpointRDD$.writePartitionToCheckpointFile(ReliableCheckpointRDD.scala:174)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1.apply(ReliableCheckpointRDD.scala:136)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11728 ] - [ INFO ]  Stage 2 was cancelled
2016-09-27 16:17:04  [ dag-scheduler-event-loop:11731 ] - [ INFO ]  ResultStage 2 (collect at RDDSuite.scala:273) failed in 0.232 s
2016-09-27 16:17:04  [ task-result-getter-3:11735 ] - [ INFO ]  Lost task 2.0 in stage 2.0 (TID 8) on executor localhost: java.lang.NullPointerException (null) [duplicate 1]
2016-09-27 16:17:04  [ task-result-getter-3:11736 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-27 16:17:04  [ task-result-getter-1:11738 ] - [ INFO ]  Lost task 0.0 in stage 2.0 (TID 6) on executor localhost: java.lang.NullPointerException (null) [duplicate 2]
2016-09-27 16:17:04  [ task-result-getter-1:11739 ] - [ INFO ]  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-27 16:17:04  [ ScalaTest-run-running-RDDSuite:11742 ] - [ INFO ]  Job 1 failed: collect at RDDSuite.scala:273, took 0.271995 s
2016-09-27 16:17:04  [ ScalaTest-run-running-RDDSuite:11747 ] - [ INFO ]  

===== FINISHED ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 16:17:04  [ ScalaTest-run:11784 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11785 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-09-27 16:17:04  [ ScalaTest-run:11785 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/api,null}
2016-09-27 16:17:04  [ ScalaTest-run:11785 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/,null}
2016-09-27 16:17:04  [ ScalaTest-run:11786 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/static,null}
2016-09-27 16:17:04  [ ScalaTest-run:11786 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11786 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2016-09-27 16:17:04  [ ScalaTest-run:11786 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11787 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/executors,null}
2016-09-27 16:17:04  [ ScalaTest-run:11787 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11787 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/environment,null}
2016-09-27 16:17:04  [ ScalaTest-run:11787 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11788 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
2016-09-27 16:17:04  [ ScalaTest-run:11788 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11788 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/storage,null}
2016-09-27 16:17:04  [ ScalaTest-run:11788 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11789 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
2016-09-27 16:17:04  [ ScalaTest-run:11789 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11789 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
2016-09-27 16:17:04  [ ScalaTest-run:11789 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11790 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/stages,null}
2016-09-27 16:17:04  [ ScalaTest-run:11790 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11790 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/job,null}
2016-09-27 16:17:04  [ ScalaTest-run:11790 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs/json,null}
2016-09-27 16:17:04  [ ScalaTest-run:11790 ] - [ INFO ]  stopped o.e.j.s.ServletContextHandler{/jobs,null}
2016-09-27 16:17:04  [ ScalaTest-run:11845 ] - [ INFO ]  Stopped Spark web UI at http://192.168.199.144:4040
2016-09-27 16:17:04  [ dispatcher-event-loop-2:11880 ] - [ INFO ]  MapOutputTrackerMasterEndpoint stopped!
2016-09-27 16:17:04  [ ScalaTest-run:11986 ] - [ INFO ]  MemoryStore cleared
2016-09-27 16:17:04  [ ScalaTest-run:11989 ] - [ INFO ]  BlockManager stopped
2016-09-27 16:17:04  [ ScalaTest-run:12015 ] - [ INFO ]  BlockManagerMaster stopped
2016-09-27 16:17:04  [ dispatcher-event-loop-0:12025 ] - [ INFO ]  OutputCommitCoordinator stopped!
2016-09-27 16:17:04  [ ScalaTest-run:12037 ] - [ INFO ]  Successfully stopped SparkContext
2016-09-27 16:17:04  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:12038 ] - [ INFO ]  Shutting down remote daemon.
2016-09-27 16:17:04  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:12042 ] - [ INFO ]  Remote daemon shut down; proceeding with flushing remote transports.
2016-09-27 16:17:04  [ Thread-3:12064 ] - [ INFO ]  Shutdown hook called
2016-09-27 16:17:04  [ Thread-3:12068 ] - [ INFO ]  Deleting directory C:\Users\ning\AppData\Local\Temp\spark-0e443fec-1f6a-453d-9502-49ac8a60912e
2016-09-27 17:32:01  [ ScalaTest-run:0 ] - [ INFO ]  Running Spark version 1.6.1
2016-09-27 17:32:03  [ ScalaTest-run:1795 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-27 17:32:04  [ ScalaTest-run:2859 ] - [ INFO ]  Changing view acls to: ning
2016-09-27 17:32:04  [ ScalaTest-run:2861 ] - [ INFO ]  Changing modify acls to: ning
2016-09-27 17:32:04  [ ScalaTest-run:2865 ] - [ INFO ]  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ning); users with modify permissions: Set(ning)
2016-09-27 17:32:10  [ ScalaTest-run:9339 ] - [ INFO ]  Successfully started service 'sparkDriver' on port 52804.
2016-09-27 17:32:11  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:10373 ] - [ INFO ]  Slf4jLogger started
2016-09-27 17:32:11  [ sparkDriverActorSystem-akka.actor.default-dispatcher-4:10536 ] - [ INFO ]  Starting remoting
2016-09-27 17:32:12  [ sparkDriverActorSystem-akka.actor.default-dispatcher-2:11108 ] - [ INFO ]  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.199.144:52817]
2016-09-27 17:32:12  [ ScalaTest-run:11123 ] - [ INFO ]  Successfully started service 'sparkDriverActorSystem' on port 52817.
2016-09-27 17:32:12  [ ScalaTest-run:11178 ] - [ INFO ]  Registering MapOutputTracker
2016-09-27 17:32:12  [ ScalaTest-run:11289 ] - [ INFO ]  Registering BlockManagerMaster
2016-09-27 17:32:12  [ ScalaTest-run:11334 ] - [ INFO ]  Created local directory at C:\Users\ning\AppData\Local\Temp\blockmgr-a004e432-a575-4906-93c9-fb82ad61adf9
2016-09-27 17:32:12  [ ScalaTest-run:11424 ] - [ INFO ]  MemoryStore started with capacity 1117.9 MB
2016-09-27 17:32:12  [ ScalaTest-run:11638 ] - [ INFO ]  Registering OutputCommitCoordinator
2016-09-27 17:32:13  [ ScalaTest-run:12389 ] - [ INFO ]  jetty-8.1.14.v20131031
2016-09-27 17:32:13  [ ScalaTest-run:12464 ] - [ INFO ]  Started SelectChannelConnector@0.0.0.0:4040
2016-09-27 17:32:13  [ ScalaTest-run:12464 ] - [ INFO ]  Successfully started service 'SparkUI' on port 4040.
2016-09-27 17:32:13  [ ScalaTest-run:12471 ] - [ INFO ]  Started SparkUI at http://192.168.199.144:4040
2016-09-27 17:32:14  [ ScalaTest-run:13444 ] - [ INFO ]  Starting executor ID driver on host localhost
2016-09-27 17:32:14  [ ScalaTest-run:13557 ] - [ INFO ]  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52836.
2016-09-27 17:32:14  [ ScalaTest-run:13559 ] - [ INFO ]  Server created on 52836
2016-09-27 17:32:14  [ ScalaTest-run:13563 ] - [ INFO ]  Trying to register BlockManager
2016-09-27 17:32:14  [ dispatcher-event-loop-2:13570 ] - [ INFO ]  Registering block manager localhost:52836 with 1117.9 MB RAM, BlockManagerId(driver, localhost, 52836)
2016-09-27 17:32:14  [ ScalaTest-run:13575 ] - [ INFO ]  Registered BlockManager
2016-09-27 17:32:16  [ ScalaTest-run-running-RDDSuite:15163 ] - [ INFO ]  

===== TEST OUTPUT FOR ning.spark.suite.RDDSuite: 'RDD' =====

2016-09-27 17:32:18  [ ScalaTest-run-running-RDDSuite:17310 ] - [ INFO ]  Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 107.7 KB)
2016-09-27 17:32:18  [ ScalaTest-run-running-RDDSuite:17451 ] - [ INFO ]  Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 117.5 KB)
2016-09-27 17:32:18  [ dispatcher-event-loop-0:17461 ] - [ INFO ]  Added broadcast_0_piece0 in memory on localhost:52836 (size: 9.8 KB, free: 1117.9 MB)
2016-09-27 17:32:19  [ ScalaTest-run-running-RDDSuite:17751 ] - [ INFO ]  Created broadcast 0 from textFile at RDDSuite.scala:258
2016-09-27 17:32:19  [ ScalaTest-run-running-RDDSuite:18203 ] - [ ERROR ]  Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:278)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:300)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:293)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$33.apply(SparkContext.scala:1015)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:331)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:330)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply$mcV$sp(RDDSuite.scala:261)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:267)
	at ning.spark.suite.RDDSuite$$anonfun$24.apply(RDDSuite.scala:267)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at ning.spark.suite.SparkFunSuite.withFixture(SparkFunSuite.scala:16)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at ning.spark.suite.RDDSuite.org$scalatest$BeforeAndAfterAll$$super$run(RDDSuite.scala:27)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at ning.spark.suite.RDDSuite.run(RDDSuite.scala:27)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.run(Runner.scala:883)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
2016-09-27 17:32:21  [ ScalaTest-run-running-RDDSuite:20025 ] - [ WARN ]  Your hostname, ning-PC resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:c790%net10, but we couldn't find any external IP address!
2016-09-27 17:32:23  [ ScalaTest-run-running-RDDSuite:21815 ] - [ INFO ]  Total input paths to process : 1
2016-09-27 17:32:27  [ ScalaTest-run-running-RDDSuite:26139 ] - [ INFO ]  Starting job: collect at RDDSuite.scala:266
2016-09-27 17:32:49  [ dag-scheduler-event-loop:48412 ] - [ INFO ]  Registering RDD 3 (map at RDDSuite.scala:260)
2016-09-27 17:32:49  [ dag-scheduler-event-loop:48415 ] - [ INFO ]  Registering RDD 5 (map at RDDSuite.scala:262)
2016-09-27 17:32:49  [ dag-scheduler-event-loop:48415 ] - [ INFO ]  Registering RDD 7 (map at RDDSuite.scala:264)
2016-09-27 17:34:08  [ dag-scheduler-event-loop:126985 ] - [ INFO ]  Got job 0 (collect at RDDSuite.scala:266) with 3 output partitions
2016-09-27 17:34:08  [ dag-scheduler-event-loop:127117 ] - [ INFO ]  Final stage: ResultStage 3 (collect at RDDSuite.scala:266)
2016-09-27 17:34:08  [ dag-scheduler-event-loop:127255 ] - [ INFO ]  Parents of final stage: List(ShuffleMapStage 2)
2016-09-27 17:34:21  [ dag-scheduler-event-loop:140215 ] - [ INFO ]  Missing parents: List(ShuffleMapStage 2)
2016-09-27 17:34:24  [ dag-scheduler-event-loop:143168 ] - [ INFO ]  Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at RDDSuite.scala:260), which has no missing parents
2016-09-27 17:34:24  [ dag-scheduler-event-loop:143396 ] - [ INFO ]  Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 121.6 KB)
2016-09-27 17:34:24  [ dag-scheduler-event-loop:143410 ] - [ INFO ]  Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 124.0 KB)
2016-09-27 17:34:24  [ dispatcher-event-loop-3:143414 ] - [ INFO ]  Added broadcast_1_piece0 in memory on localhost:52836 (size: 2.3 KB, free: 1117.9 MB)
2016-09-27 17:34:24  [ dag-scheduler-event-loop:143416 ] - [ INFO ]  Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2016-09-27 17:34:24  [ dag-scheduler-event-loop:143446 ] - [ INFO ]  Submitting 3 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at RDDSuite.scala:260)
2016-09-27 17:34:24  [ dag-scheduler-event-loop:143456 ] - [ INFO ]  Adding task set 0.0 with 3 tasks
2016-09-27 17:34:30  [ dispatcher-event-loop-0:149006 ] - [ INFO ]  Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2128 bytes)
2016-09-27 17:34:30  [ dispatcher-event-loop-0:149019 ] - [ INFO ]  Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2128 bytes)
2016-09-27 17:34:30  [ dispatcher-event-loop-0:149021 ] - [ INFO ]  Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2128 bytes)
